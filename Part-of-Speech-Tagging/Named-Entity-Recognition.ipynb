{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377bf720",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "<div class='alert alert-success' style='margin:20px'> Named Entity Recognition (NER) seeks to locate and classify named entity mentions in unstructured text into pre-defined categories such as the person names, organisations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n",
    "    \n",
    "**Let's Explore NER with spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54264712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import spacy and load english language library\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp=en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49446f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to show entities\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text + '-' + ent.label_ + '-' + spacy.explain(ent.label_))\n",
    "    else:\n",
    "        print(\"No entities found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927ab0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entities found\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u\"Hey, How are you?\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4681ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi-GPE-Countries, cities, states\n",
      "India Gate-FAC-Buildings, airports, highways, bridges, etc.\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u\"May i go to Delhi to see India Gate?\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087934e",
   "metadata": {},
   "source": [
    "## Entity annotations\n",
    "`Doc.ents` are token spans with their own set of annotations.\n",
    "<table>\n",
    "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
    "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
    "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
    "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced9c48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 3 4 13 16 CARDINAL\n",
      "Microsoft 6 7 27 36 ORG\n"
     ]
    }
   ],
   "source": [
    "doc1=nlp(u\"Should I buy 500 shares of Microsoft company?\")\n",
    "for ent in doc1.ents:\n",
    "    print(ent.text, ent.start, ent.end,ent.start_char,ent.end_char,ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ca3a79",
   "metadata": {},
   "source": [
    "## NER Tags\n",
    "Tags are accessible through the `.label_` property of an entity.\n",
    "<table>\n",
    "<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
    "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
    "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
    "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
    "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
    "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
    "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
    "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
    "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
    "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
    "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
    "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
    "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
    "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
    "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
    "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
    "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
    "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6fa88",
   "metadata": {},
   "source": [
    "___\n",
    "## Adding a Named Entity to a Span\n",
    "Normally we would have spaCy build a library of named entities by training it on several samples of text.<br>In this case, we only want to add one value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7f11da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.K.-GPE-Countries, cities, states\n",
      "$60 million-MONEY-Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u\"Tesla to build a U.K. factory for $60 million\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f170b4",
   "metadata": {},
   "source": [
    "As you can see above Tesla does not have any entity, but we can add it's entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df0c2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34e2f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG=doc.vocab.strings[\"ORG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "270411a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c9d1414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ORG'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab[ORG].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73aad8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ent=Span(doc,0,1,label=ORG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcaf277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents=list(doc.ents) + [new_ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3934b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla-ORG-Companies, agencies, institutions, etc.\n",
      "U.K.-GPE-Countries, cities, states\n",
      "$60 million-MONEY-Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f4204c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can see Tesla has an entity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a9f23",
   "metadata": {},
   "source": [
    "### Adding Named Entities to all matching spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6838b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No entities found\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(u\"Our company created a brand new vaccum cleaner.\"\n",
    "        u\"This new vaccum-cleaner is the best in show.\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd6c54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "788727a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher=PhraseMatcher(nlp.vocab)\n",
    "\n",
    "phrase_list=['vaccum cleaner','vaccum-cleaner']\n",
    "\n",
    "phrase_patterns=[nlp(text) for text in phrase_list]\n",
    "\n",
    "matcher.add('newproduct',[*phrase_patterns])\n",
    "found_matches=matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3b080c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2689272359382549672, 6, 8), (2689272359382549672, 11, 14)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c99644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove('newproduct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0f9df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e651b468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROD=doc.vocab.strings[\"PRODUCT\"]\n",
    "PROD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e608eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ents=[Span(doc,match[1],match[2],label=PROD) for match in found_matches ]\n",
    "\n",
    "doc.ents=list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "417e992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vaccum cleaner-PRODUCT-Objects, vehicles, foods, etc. (not services)\n",
      "vaccum-cleaner-PRODUCT-Objects, vehicles, foods, etc. (not services)\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)   # We have successfully added new entity to our spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59f07f3",
   "metadata": {},
   "source": [
    "### Counting Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8e89f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u\"Originally i paid $20 for this toy car, but now this marked down to $14.6.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cab29117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 14.6]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ent for ent in doc.ents if ent.label_=='MONEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "238ee7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ent for ent in doc.ents if ent.label_==\"MONEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1defa4f",
   "metadata": {},
   "source": [
    "## Noun Chunks\n",
    "`Doc.noun_chunks` are *base noun phrases*: token spans that include the noun and words describing the noun. Noun chunks cannot be nested, cannot overlap, and do not involve prepositional phrases or relative clauses.<br>\n",
    "Where `Doc.ents` rely on the **ner** pipeline component, `Doc.noun_chunks` are provided by the **parser**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1edaa2",
   "metadata": {},
   "source": [
    "### `noun_chunks` components:\n",
    "<table>\n",
    "<tr><td>`.text`</td><td>The original noun chunk text.</td></tr>\n",
    "<tr><td>`.root.text`</td><td>The original text of the word connecting the noun chunk to the rest of the parse.</td></tr>\n",
    "<tr><td>`.root.dep_`</td><td>Dependency relation connecting the root to its head.</td></tr>\n",
    "<tr><td>`.root.head.text`</td><td>The text of the root token's head.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fea469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

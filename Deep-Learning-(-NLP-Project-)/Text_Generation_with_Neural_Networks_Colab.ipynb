{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Text-Generation-with-Neural-Networks-Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryatomarAI/Natural-Language-Processing-with-python/blob/main/Deep-Learning-(-NLP-Project-)/Text_Generation_with_Neural_Networks_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "135187f5"
      },
      "source": [
        "# Text Generation with Neural Networks\n",
        "we will be using RNN(Recurrent Neural Networks)\n",
        "\n",
        "## RNN:\n",
        "A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Derived from feedforward neural networks, RNNs can use their internal state (memory) to process variable length sequences of inputs.\n",
        "\n",
        "## LSTM\n",
        "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems. This is a behavior required in complex problem domains like machine translation, speech recognition, and more.\n"
      ],
      "id": "135187f5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a10bd8fb"
      },
      "source": [
        "## DATA \n",
        "we are using Moby Dick's first four chapter for text generation. Moby Dick is Novel by Herman Melville."
      ],
      "id": "a10bd8fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcb51d4e"
      },
      "source": [
        "### Import Tools and load data"
      ],
      "id": "dcb51d4e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0339f16"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "nlp=spacy.load(\"en\",disable=['parser','tagger','ner'])"
      ],
      "id": "e0339f16",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyjLPETptlKt",
        "outputId": "535c58ed-f0e9-474a-b070-c154e5558c3b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "GyjLPETptlKt",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95e70565",
        "outputId": "a4e1c23a-366a-412b-c07f-5f6069d3a997"
      },
      "source": [
        "nlp.max_length"
      ],
      "id": "95e70565",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "201d2b81"
      },
      "source": [
        "## create a function which will seperate punctuations from the doc file\n",
        "def seperate_punc(doc_file):\n",
        "    return [token.text.lower() for token in nlp(doc_file) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
      ],
      "id": "201d2b81",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3779280d"
      },
      "source": [
        "with open(\"drive/MyDrive/moby_dick_four_chapters.txt\") as f:\n",
        "    doc=f.read()"
      ],
      "id": "3779280d",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48f11315"
      },
      "source": [
        "tokens=seperate_punc(doc)"
      ],
      "id": "48f11315",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96663e99",
        "outputId": "45fc18b0-0626-4e7c-dcbc-470f9a69dec2"
      },
      "source": [
        "len(tokens)"
      ],
      "id": "96663e99",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7364773",
        "outputId": "2345cd70-ff54-4dad-d662-750499978bce"
      },
      "source": [
        "tokens[:15]"
      ],
      "id": "f7364773",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['call',\n",
              " 'me',\n",
              " 'ishmael',\n",
              " 'some',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'never',\n",
              " 'mind',\n",
              " 'how',\n",
              " 'long',\n",
              " 'precisely',\n",
              " 'having',\n",
              " 'little',\n",
              " 'or',\n",
              " 'no']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83537a36"
      },
      "source": [
        "## Create Sequences of tokens"
      ],
      "id": "83537a36"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab981222"
      },
      "source": [
        "# organise into sequences of tokens\n",
        "train_len=25+1\n",
        "\n",
        "# empty list of sequences\n",
        "text_sequences=[]\n",
        "\n",
        "for i in range(train_len,len(tokens)):\n",
        "    seq=tokens[i-train_len:i]\n",
        "    \n",
        "    text_sequences.append(seq)"
      ],
      "id": "ab981222",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3c507b3",
        "outputId": "bc2ce267-8e4d-45db-a170-a0cabf6d38be"
      },
      "source": [
        "type(text_sequences)"
      ],
      "id": "f3c507b3",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9d8d947",
        "outputId": "5263fb3e-a643-4ed2-ee8f-7c395cfa9b88"
      },
      "source": [
        "text_sequences[0:2]"
      ],
      "id": "a9d8d947",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['call',\n",
              "  'me',\n",
              "  'ishmael',\n",
              "  'some',\n",
              "  'years',\n",
              "  'ago',\n",
              "  'never',\n",
              "  'mind',\n",
              "  'how',\n",
              "  'long',\n",
              "  'precisely',\n",
              "  'having',\n",
              "  'little',\n",
              "  'or',\n",
              "  'no',\n",
              "  'money',\n",
              "  'in',\n",
              "  'my',\n",
              "  'purse',\n",
              "  'and',\n",
              "  'nothing',\n",
              "  'particular',\n",
              "  'to',\n",
              "  'interest',\n",
              "  'me',\n",
              "  'on'],\n",
              " ['me',\n",
              "  'ishmael',\n",
              "  'some',\n",
              "  'years',\n",
              "  'ago',\n",
              "  'never',\n",
              "  'mind',\n",
              "  'how',\n",
              "  'long',\n",
              "  'precisely',\n",
              "  'having',\n",
              "  'little',\n",
              "  'or',\n",
              "  'no',\n",
              "  'money',\n",
              "  'in',\n",
              "  'my',\n",
              "  'purse',\n",
              "  'and',\n",
              "  'nothing',\n",
              "  'particular',\n",
              "  'to',\n",
              "  'interest',\n",
              "  'me',\n",
              "  'on',\n",
              "  'shore']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1b0d8f75",
        "outputId": "88fb59bf-bc28-4a39-ac7a-a9e5eced3b93"
      },
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "id": "1b0d8f75",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "832ffcff",
        "outputId": "7914d2b3-c521-4c02-84f7-e41c2761d401"
      },
      "source": [
        "\" \".join(text_sequences[1])"
      ],
      "id": "832ffcff",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d656119c",
        "outputId": "d58090d1-5703-444f-92fb-ccc615f44995"
      },
      "source": [
        "len(text_sequences)"
      ],
      "id": "d656119c",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e58cc64"
      },
      "source": [
        "## Keras Tokenization\n",
        "This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf..."
      ],
      "id": "8e58cc64"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "268e65ca"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "id": "268e65ca",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be3408c0"
      },
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences=tokenizer.texts_to_sequences(text_sequences)"
      ],
      "id": "be3408c0",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0bf2d1c"
      },
      "source": [
        "**fit_on_texts** Updates internal vocabulary based on a list of texts. This method creates the vocabulary index based on word frequency. So if you give it something like, `\"The cat sat on the mat.\"` It will create a dictionary s.t. `word_index[\"the\"] = 1`; `word_index[\"cat\"] = 2` it is word -> index dictionary so every word gets a unique integer value. 0 is reserved for padding. So lower integer means more frequent word (often the first few are stop words because they appear a lot).\n",
        "\n",
        "**texts_to_sequences** Transforms each text in texts to a sequence of integers. So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary. Nothing more, nothing less, certainly no magic involved."
      ],
      "id": "e0bf2d1c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "982ca673",
        "outputId": "7da67f6f-c85c-4569-fa4d-0457c76a6214"
      },
      "source": [
        "sequences[0]"
      ],
      "id": "982ca673",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[956,\n",
              " 14,\n",
              " 263,\n",
              " 51,\n",
              " 261,\n",
              " 408,\n",
              " 87,\n",
              " 219,\n",
              " 129,\n",
              " 111,\n",
              " 954,\n",
              " 260,\n",
              " 50,\n",
              " 43,\n",
              " 38,\n",
              " 315,\n",
              " 7,\n",
              " 23,\n",
              " 546,\n",
              " 3,\n",
              " 150,\n",
              " 259,\n",
              " 6,\n",
              " 2712,\n",
              " 14,\n",
              " 24]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdc61f77",
        "outputId": "70bb61b3-b0e3-4b29-d04d-9e4c660a773d"
      },
      "source": [
        "len(tokenizer.index_word)"
      ],
      "id": "bdc61f77",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16bd657c",
        "outputId": "5ef7430f-6a6f-4303-a508-56972577c87b"
      },
      "source": [
        "list(tokenizer.index_word.items())[:50]"
      ],
      "id": "16bd657c",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 'the'),\n",
              " (2, 'a'),\n",
              " (3, 'and'),\n",
              " (4, 'of'),\n",
              " (5, 'i'),\n",
              " (6, 'to'),\n",
              " (7, 'in'),\n",
              " (8, 'it'),\n",
              " (9, 'that'),\n",
              " (10, 'he'),\n",
              " (11, 'his'),\n",
              " (12, 'was'),\n",
              " (13, 'but'),\n",
              " (14, 'me'),\n",
              " (15, 'with'),\n",
              " (16, 'as'),\n",
              " (17, 'at'),\n",
              " (18, 'this'),\n",
              " (19, 'you'),\n",
              " (20, 'is'),\n",
              " (21, 'all'),\n",
              " (22, 'for'),\n",
              " (23, 'my'),\n",
              " (24, 'on'),\n",
              " (25, 'be'),\n",
              " (26, \"'s\"),\n",
              " (27, 'not'),\n",
              " (28, 'from'),\n",
              " (29, 'there'),\n",
              " (30, 'one'),\n",
              " (31, 'up'),\n",
              " (32, 'what'),\n",
              " (33, 'him'),\n",
              " (34, 'so'),\n",
              " (35, 'bed'),\n",
              " (36, 'now'),\n",
              " (37, 'about'),\n",
              " (38, 'no'),\n",
              " (39, 'into'),\n",
              " (40, 'by'),\n",
              " (41, 'were'),\n",
              " (42, 'out'),\n",
              " (43, 'or'),\n",
              " (44, 'harpooneer'),\n",
              " (45, 'had'),\n",
              " (46, 'then'),\n",
              " (47, 'have'),\n",
              " (48, 'an'),\n",
              " (49, 'upon'),\n",
              " (50, 'little')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95536231",
        "outputId": "08c7850c-34cc-4255-a530-eb884edfb0b0"
      },
      "source": [
        "len(sequences)"
      ],
      "id": "95536231",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53bf6a15",
        "outputId": "a62a3b63-dae8-4677-c90c-d6a80df9c225"
      },
      "source": [
        "tokenizer.word_counts"
      ],
      "id": "53bf6a15",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('call', 27),\n",
              "             ('me', 2471),\n",
              "             ('ishmael', 133),\n",
              "             ('some', 758),\n",
              "             ('years', 135),\n",
              "             ('ago', 84),\n",
              "             ('never', 449),\n",
              "             ('mind', 164),\n",
              "             ('how', 321),\n",
              "             ('long', 374),\n",
              "             ('precisely', 37),\n",
              "             ('having', 142),\n",
              "             ('little', 767),\n",
              "             ('or', 950),\n",
              "             ('no', 1003),\n",
              "             ('money', 120),\n",
              "             ('in', 5647),\n",
              "             ('my', 1786),\n",
              "             ('purse', 71),\n",
              "             ('and', 9646),\n",
              "             ('nothing', 281),\n",
              "             ('particular', 152),\n",
              "             ('to', 6497),\n",
              "             ('interest', 24),\n",
              "             ('on', 1716),\n",
              "             ('shore', 26),\n",
              "             ('i', 7150),\n",
              "             ('thought', 676),\n",
              "             ('would', 702),\n",
              "             ('sail', 104),\n",
              "             ('about', 1014),\n",
              "             ('a', 10377),\n",
              "             ('see', 416),\n",
              "             ('the', 15540),\n",
              "             ('watery', 26),\n",
              "             ('part', 234),\n",
              "             ('of', 8287),\n",
              "             ('world', 234),\n",
              "             ('it', 4238),\n",
              "             ('is', 1950),\n",
              "             ('way', 390),\n",
              "             ('have', 806),\n",
              "             ('driving', 26),\n",
              "             ('off', 416),\n",
              "             ('spleen', 26),\n",
              "             ('regulating', 26),\n",
              "             ('circulation', 26),\n",
              "             ('whenever', 130),\n",
              "             ('find', 78),\n",
              "             ('myself', 416),\n",
              "             ('growing', 26),\n",
              "             ('grim', 26),\n",
              "             ('mouth', 130),\n",
              "             ('damp', 78),\n",
              "             ('drizzly', 26),\n",
              "             ('november', 26),\n",
              "             ('soul', 78),\n",
              "             ('involuntarily', 52),\n",
              "             ('pausing', 52),\n",
              "             ('before', 364),\n",
              "             ('coffin', 104),\n",
              "             ('warehouses', 52),\n",
              "             ('bringing', 26),\n",
              "             ('up', 1237),\n",
              "             ('rear', 26),\n",
              "             ('every', 182),\n",
              "             ('funeral', 26),\n",
              "             ('meet', 26),\n",
              "             ('especially', 104),\n",
              "             ('hypos', 26),\n",
              "             ('get', 364),\n",
              "             ('such', 572),\n",
              "             ('an', 806),\n",
              "             ('upper', 26),\n",
              "             ('hand', 312),\n",
              "             ('that', 3770),\n",
              "             ('requires', 52),\n",
              "             ('strong', 78),\n",
              "             ('moral', 26),\n",
              "             ('principle', 26),\n",
              "             ('prevent', 26),\n",
              "             ('from', 1508),\n",
              "             ('deliberately', 26),\n",
              "             ('stepping', 26),\n",
              "             ('into', 988),\n",
              "             ('street', 104),\n",
              "             ('methodically', 26),\n",
              "             ('knocking', 26),\n",
              "             ('people', 52),\n",
              "             (\"'s\", 1691),\n",
              "             ('hats', 26),\n",
              "             ('then', 832),\n",
              "             ('account', 78),\n",
              "             ('high', 130),\n",
              "             ('time', 520),\n",
              "             ('sea', 546),\n",
              "             ('as', 2366),\n",
              "             ('soon', 234),\n",
              "             ('can', 338),\n",
              "             ('this', 2158),\n",
              "             ('substitute', 26),\n",
              "             ('for', 1820),\n",
              "             ('pistol', 26),\n",
              "             ('ball', 26),\n",
              "             ('with', 2392),\n",
              "             ('philosophical', 26),\n",
              "             ('flourish', 26),\n",
              "             ('cato', 26),\n",
              "             ('throws', 26),\n",
              "             ('himself', 338),\n",
              "             ('upon', 780),\n",
              "             ('his', 3139),\n",
              "             ('sword', 78),\n",
              "             ('quietly', 78),\n",
              "             ('take', 260),\n",
              "             ('ship', 182),\n",
              "             ('there', 1456),\n",
              "             ('surprising', 26),\n",
              "             ('if', 728),\n",
              "             ('they', 728),\n",
              "             ('but', 2652),\n",
              "             ('knew', 130),\n",
              "             ('almost', 286),\n",
              "             ('all', 1872),\n",
              "             ('men', 130),\n",
              "             ('their', 390),\n",
              "             ('degree', 78),\n",
              "             ('other', 494),\n",
              "             ('cherish', 26),\n",
              "             ('very', 494),\n",
              "             ('nearly', 52),\n",
              "             ('same', 312),\n",
              "             ('feelings', 26),\n",
              "             ('towards', 260),\n",
              "             ('ocean', 52),\n",
              "             ('now', 1040),\n",
              "             ('your', 442),\n",
              "             ('insular', 26),\n",
              "             ('city', 104),\n",
              "             ('manhattoes', 26),\n",
              "             ('belted', 26),\n",
              "             ('round', 364),\n",
              "             ('by', 962),\n",
              "             ('wharves', 26),\n",
              "             ('indian', 52),\n",
              "             ('isles', 26),\n",
              "             ('coral', 26),\n",
              "             ('reefs', 26),\n",
              "             ('commerce', 26),\n",
              "             ('surrounds', 26),\n",
              "             ('her', 156),\n",
              "             ('surf', 26),\n",
              "             ('right', 156),\n",
              "             ('left', 78),\n",
              "             ('streets', 208),\n",
              "             ('you', 2158),\n",
              "             ('waterward', 52),\n",
              "             ('its', 156),\n",
              "             ('extreme', 26),\n",
              "             ('downtown', 26),\n",
              "             ('battery', 52),\n",
              "             ('where', 364),\n",
              "             ('noble', 52),\n",
              "             ('mole', 26),\n",
              "             ('washed', 52),\n",
              "             ('waves', 26),\n",
              "             ('cooled', 26),\n",
              "             ('breezes', 26),\n",
              "             ('which', 572),\n",
              "             ('few', 104),\n",
              "             ('hours', 130),\n",
              "             ('previous', 104),\n",
              "             ('were', 962),\n",
              "             ('out', 956),\n",
              "             ('sight', 104),\n",
              "             ('land', 208),\n",
              "             ('look', 156),\n",
              "             ('at', 2184),\n",
              "             ('crowds', 52),\n",
              "             ('water', 234),\n",
              "             ('gazers', 26),\n",
              "             ('circumambulate', 26),\n",
              "             ('dreamy', 26),\n",
              "             ('sabbath', 52),\n",
              "             ('afternoon', 52),\n",
              "             ('go', 494),\n",
              "             ('corlears', 26),\n",
              "             ('hook', 26),\n",
              "             ('coenties', 26),\n",
              "             ('slip', 26),\n",
              "             ('thence', 52),\n",
              "             ('whitehall', 26),\n",
              "             ('northward', 26),\n",
              "             ('what', 1118),\n",
              "             ('do', 702),\n",
              "             ('see?--posted', 26),\n",
              "             ('like', 732),\n",
              "             ('silent', 52),\n",
              "             ('sentinels', 26),\n",
              "             ('around', 78),\n",
              "             ('town', 156),\n",
              "             ('stand', 182),\n",
              "             ('thousands', 52),\n",
              "             ('mortal', 26),\n",
              "             ('fixed', 78),\n",
              "             ('reveries', 52),\n",
              "             ('leaning', 52),\n",
              "             ('against', 234),\n",
              "             ('spiles', 26),\n",
              "             ('seated', 52),\n",
              "             ('pier', 26),\n",
              "             ('heads', 338),\n",
              "             ('looking', 312),\n",
              "             ('over', 702),\n",
              "             ('bulwarks', 52),\n",
              "             ('ships', 78),\n",
              "             ('china', 26),\n",
              "             ('aloft', 52),\n",
              "             ('rigging', 26),\n",
              "             ('striving', 26),\n",
              "             ('still', 364),\n",
              "             ('better', 208),\n",
              "             ('seaward', 26),\n",
              "             ('peep', 26),\n",
              "             ('these', 494),\n",
              "             ('are', 416),\n",
              "             ('landsmen', 26),\n",
              "             ('week', 52),\n",
              "             ('days', 104),\n",
              "             ('pent', 26),\n",
              "             ('lath', 26),\n",
              "             ('plaster', 52),\n",
              "             ('tied', 26),\n",
              "             ('counters', 26),\n",
              "             ('nailed', 26),\n",
              "             ('benches', 26),\n",
              "             ('clinched', 26),\n",
              "             ('desks', 26),\n",
              "             ('green', 130),\n",
              "             ('fields', 26),\n",
              "             ('gone', 52),\n",
              "             ('here', 598),\n",
              "             ('come', 338),\n",
              "             ('more', 494),\n",
              "             ('pacing', 26),\n",
              "             ('straight', 104),\n",
              "             ('seemingly', 26),\n",
              "             ('bound', 52),\n",
              "             ('dive', 26),\n",
              "             ('strange', 182),\n",
              "             ('will', 260),\n",
              "             ('content', 52),\n",
              "             ('them', 442),\n",
              "             ('extremest', 26),\n",
              "             ('limit', 26),\n",
              "             ('loitering', 26),\n",
              "             ('under', 260),\n",
              "             ('shady', 26),\n",
              "             ('lee', 26),\n",
              "             ('yonder', 52),\n",
              "             ('not', 1534),\n",
              "             ('suffice', 26),\n",
              "             ('must', 442),\n",
              "             ('just', 390),\n",
              "             ('nigh', 104),\n",
              "             ('possibly', 26),\n",
              "             ('without', 182),\n",
              "             ('falling', 52),\n",
              "             ('miles', 78),\n",
              "             ('leagues', 26),\n",
              "             ('inlanders', 26),\n",
              "             ('lanes', 26),\n",
              "             ('alleys', 26),\n",
              "             ('avenues', 26),\n",
              "             ('north', 52),\n",
              "             ('east', 26),\n",
              "             ('south', 156),\n",
              "             ('west', 26),\n",
              "             ('yet', 416),\n",
              "             ('unite', 26),\n",
              "             ('tell', 442),\n",
              "             ('does', 156),\n",
              "             ('magnetic', 26),\n",
              "             ('virtue', 26),\n",
              "             ('needles', 26),\n",
              "             ('compasses', 26),\n",
              "             ('those', 234),\n",
              "             ('attract', 26),\n",
              "             ('thither', 26),\n",
              "             ('once', 208),\n",
              "             ('say', 286),\n",
              "             ('country', 78),\n",
              "             ('lakes', 26),\n",
              "             ('any', 364),\n",
              "             ('path', 26),\n",
              "             ('please', 52),\n",
              "             ('ten', 52),\n",
              "             ('one', 1300),\n",
              "             ('carries', 26),\n",
              "             ('down', 468),\n",
              "             ('dale', 26),\n",
              "             ('leaves', 52),\n",
              "             ('pool', 26),\n",
              "             ('stream', 78),\n",
              "             ('magic', 52),\n",
              "             ('let', 156),\n",
              "             ('most', 468),\n",
              "             ('absent', 26),\n",
              "             ('minded', 26),\n",
              "             ('be', 1716),\n",
              "             ('plunged', 52),\n",
              "             ('deepest', 26),\n",
              "             ('man', 572),\n",
              "             ('legs', 104),\n",
              "             ('set', 156),\n",
              "             ('feet', 182),\n",
              "             ('going', 260),\n",
              "             ('he', 3247),\n",
              "             ('infallibly', 26),\n",
              "             ('lead', 78),\n",
              "             ('region', 26),\n",
              "             ('should', 286),\n",
              "             ('ever', 338),\n",
              "             ('athirst', 26),\n",
              "             ('great', 376),\n",
              "             ('american', 78),\n",
              "             ('desert', 26),\n",
              "             ('try', 104),\n",
              "             ('experiment', 26),\n",
              "             ('caravan', 26),\n",
              "             ('happen', 26),\n",
              "             ('supplied', 26),\n",
              "             ('metaphysical', 52),\n",
              "             ('professor', 26),\n",
              "             ('yes', 104),\n",
              "             ('knows', 26),\n",
              "             ('meditation', 26),\n",
              "             ('wedded', 26),\n",
              "             ('artist', 78),\n",
              "             ('desires', 26),\n",
              "             ('paint', 26),\n",
              "             ('dreamiest', 26),\n",
              "             ('shadiest', 26),\n",
              "             ('quietest', 26),\n",
              "             ('enchanting', 26),\n",
              "             ('bit', 130),\n",
              "             ('romantic', 26),\n",
              "             ('landscape', 26),\n",
              "             ('valley', 26),\n",
              "             ('saco', 26),\n",
              "             ('chief', 52),\n",
              "             ('element', 26),\n",
              "             ('employs', 26),\n",
              "             ('trees', 26),\n",
              "             ('each', 78),\n",
              "             ('hollow', 26),\n",
              "             ('trunk', 52),\n",
              "             ('hermit', 26),\n",
              "             ('crucifix', 26),\n",
              "             ('within', 130),\n",
              "             ('sleeps', 26),\n",
              "             ('meadow', 52),\n",
              "             ('sleep', 416),\n",
              "             ('cattle', 26),\n",
              "             ('cottage', 26),\n",
              "             ('goes', 78),\n",
              "             ('sleepy', 26),\n",
              "             ('smoke', 52),\n",
              "             ('deep', 78),\n",
              "             ('distant', 78),\n",
              "             ('woodlands', 26),\n",
              "             ('winds', 78),\n",
              "             ('mazy', 26),\n",
              "             ('reaching', 52),\n",
              "             ('overlapping', 26),\n",
              "             ('spurs', 26),\n",
              "             ('mountains', 26),\n",
              "             ('bathed', 26),\n",
              "             ('hill', 52),\n",
              "             ('side', 286),\n",
              "             ('blue', 78),\n",
              "             ('though', 494),\n",
              "             ('picture', 130),\n",
              "             ('lies', 26),\n",
              "             ('thus', 52),\n",
              "             ('tranced', 26),\n",
              "             ('pine', 52),\n",
              "             ('tree', 26),\n",
              "             ('shakes', 26),\n",
              "             ('sighs', 52),\n",
              "             ('shepherd', 52),\n",
              "             ('head', 598),\n",
              "             ('vain', 26),\n",
              "             ('unless', 104),\n",
              "             ('eye', 26),\n",
              "             ('him', 1092),\n",
              "             ('visit', 26),\n",
              "             ('prairies', 26),\n",
              "             ('june', 52),\n",
              "             ('when', 650),\n",
              "             ('scores', 52),\n",
              "             ('wade', 26),\n",
              "             ('knee', 26),\n",
              "             ('among', 78),\n",
              "             ('tiger', 26),\n",
              "             ('lilies', 26),\n",
              "             ('charm', 26),\n",
              "             ('wanting?--water', 26),\n",
              "             ('drop', 26),\n",
              "             ('niagara', 26),\n",
              "             ('cataract', 26),\n",
              "             ('sand', 26),\n",
              "             ('travel', 26),\n",
              "             ('thousand', 52),\n",
              "             ('why', 286),\n",
              "             ('did', 572),\n",
              "             ('poor', 104),\n",
              "             ('poet', 26),\n",
              "             ('tennessee', 26),\n",
              "             ('suddenly', 78),\n",
              "             ('receiving', 26),\n",
              "             ('two', 338),\n",
              "             ('handfuls', 26),\n",
              "             ('silver', 26),\n",
              "             ('deliberate', 26),\n",
              "             ('whether', 182),\n",
              "             ('buy', 26),\n",
              "             ('coat', 104),\n",
              "             ('sadly', 52),\n",
              "             ('needed', 26),\n",
              "             ('invest', 26),\n",
              "             ('pedestrian', 26),\n",
              "             ('trip', 26),\n",
              "             ('rockaway', 26),\n",
              "             ('beach', 26),\n",
              "             ('robust', 52),\n",
              "             ('healthy', 52),\n",
              "             ('boy', 52),\n",
              "             ('crazy', 52),\n",
              "             ('first', 494),\n",
              "             ('voyage', 208),\n",
              "             ('passenger', 104),\n",
              "             ('yourself', 156),\n",
              "             ('feel', 78),\n",
              "             ('mystical', 26),\n",
              "             ('vibration', 26),\n",
              "             ('told', 130),\n",
              "             ('old', 754),\n",
              "             ('persians', 26),\n",
              "             ('hold', 52),\n",
              "             ('holy', 52),\n",
              "             ('greeks', 26),\n",
              "             ('give', 208),\n",
              "             ('separate', 26),\n",
              "             ('deity', 26),\n",
              "             ('own', 286),\n",
              "             ('brother', 52),\n",
              "             ('jove', 26),\n",
              "             ('surely', 26),\n",
              "             ('meaning', 78),\n",
              "             ('deeper', 26),\n",
              "             ('story', 130),\n",
              "             ('narcissus', 26),\n",
              "             ('who', 416),\n",
              "             ('because', 182),\n",
              "             ('could', 650),\n",
              "             ('grasp', 26),\n",
              "             ('tormenting', 26),\n",
              "             ('mild', 26),\n",
              "             ('image', 156),\n",
              "             ('saw', 156),\n",
              "             ('fountain', 26),\n",
              "             ('was', 2886),\n",
              "             ('drowned', 26),\n",
              "             ('we', 286),\n",
              "             ('ourselves', 52),\n",
              "             ('rivers', 26),\n",
              "             ('oceans', 26),\n",
              "             ('ungraspable', 26),\n",
              "             ('phantom', 78),\n",
              "             ('life', 78),\n",
              "             ('key', 26),\n",
              "             ('am', 156),\n",
              "             ('habit', 26),\n",
              "             ('begin', 52),\n",
              "             ('grow', 52),\n",
              "             ('hazy', 26),\n",
              "             ('eyes', 182),\n",
              "             ('conscious', 26),\n",
              "             ('lungs', 26),\n",
              "             ('mean', 130),\n",
              "             ('inferred', 52),\n",
              "             ('needs', 52),\n",
              "             ('rag', 26),\n",
              "             ('something', 312),\n",
              "             ('besides', 156),\n",
              "             ('passengers', 78),\n",
              "             ('sick', 26),\n",
              "             ('quarrelsome', 26),\n",
              "             (\"don't\", 52),\n",
              "             ('nights', 26),\n",
              "             ('enjoy', 26),\n",
              "             ('themselves', 52),\n",
              "             ('much', 442),\n",
              "             ('general', 26),\n",
              "             ('thing;--no', 26),\n",
              "             ('nor', 78),\n",
              "             ('salt', 26),\n",
              "             ('commodore', 52),\n",
              "             ('captain', 52),\n",
              "             ('cook', 52),\n",
              "             ('abandon', 26),\n",
              "             ('glory', 52),\n",
              "             ('distinction', 26),\n",
              "             ('offices', 26),\n",
              "             ('abominate', 26),\n",
              "             ('honourable', 26),\n",
              "             ('respectable', 26),\n",
              "             ('toils', 26),\n",
              "             ('trials', 26),\n",
              "             ('tribulations', 26),\n",
              "             ('kind', 78),\n",
              "             ('whatsoever', 52),\n",
              "             ('quite', 78),\n",
              "             ('care', 78),\n",
              "             ('taking', 104),\n",
              "             ('barques', 26),\n",
              "             ('brigs', 26),\n",
              "             ('schooners', 26),\n",
              "             ('cook,--though', 26),\n",
              "             ('confess', 52),\n",
              "             ('considerable', 26),\n",
              "             ('being', 390),\n",
              "             ('sort', 494),\n",
              "             ('officer', 52),\n",
              "             ('board', 78),\n",
              "             ('somehow', 78),\n",
              "             ('fancied', 26),\n",
              "             ('broiling', 26),\n",
              "             ('fowls;--though', 26),\n",
              "             ('broiled', 78),\n",
              "             ('judiciously', 26),\n",
              "             ('buttered', 26),\n",
              "             ('judgmatically', 26),\n",
              "             ('salted', 26),\n",
              "             ('peppered', 26),\n",
              "             ('speak', 130),\n",
              "             ('respectfully', 52),\n",
              "             ('reverentially', 26),\n",
              "             ('fowl', 26),\n",
              "             ('than', 390),\n",
              "             ('idolatrous', 26),\n",
              "             ('dotings', 26),\n",
              "             ('egyptians', 26),\n",
              "             ('ibis', 26),\n",
              "             ('roasted', 26),\n",
              "             ('river', 26),\n",
              "             ('horse', 52),\n",
              "             ('mummies', 26),\n",
              "             ('creatures', 26),\n",
              "             ('huge', 52),\n",
              "             ('bake', 26),\n",
              "             ('houses', 52),\n",
              "             ('pyramids', 26),\n",
              "             ('simple', 26),\n",
              "             ('sailor', 156),\n",
              "             ('mast', 78),\n",
              "             ('plumb', 26),\n",
              "             ('forecastle', 52),\n",
              "             ('royal', 26),\n",
              "             ('true', 104),\n",
              "             ('rather', 208),\n",
              "             ('order', 130),\n",
              "             ('make', 260),\n",
              "             ('jump', 52),\n",
              "             ('spar', 52),\n",
              "             ('grasshopper', 26),\n",
              "             ('may', 312),\n",
              "             ('thing', 104),\n",
              "             ('unpleasant', 26),\n",
              "             ('enough', 338),\n",
              "             ('touches', 26),\n",
              "             ('sense', 78),\n",
              "             ('honour', 26),\n",
              "             ('particularly', 52),\n",
              "             ('established', 26),\n",
              "             ('family', 26),\n",
              "             ('van', 26),\n",
              "             ('rensselaers', 26),\n",
              "             ('randolphs', 26),\n",
              "             ('hardicanutes', 26),\n",
              "             ('putting', 52),\n",
              "             ('tar', 52),\n",
              "             ('pot', 26),\n",
              "             ('been', 468),\n",
              "             ('lording', 26),\n",
              "             ('schoolmaster', 52),\n",
              "             ('making', 130),\n",
              "             ('tallest', 26),\n",
              "             ('boys', 52),\n",
              "             ('awe', 26),\n",
              "             ('transition', 52),\n",
              "             ('keen', 26),\n",
              "             ('assure', 26),\n",
              "             ('decoction', 26),\n",
              "             ('seneca', 26),\n",
              "             ('stoics', 26),\n",
              "             ('enable', 26),\n",
              "             ('grin', 52),\n",
              "             ('bear', 52),\n",
              "             ('even', 130),\n",
              "             ('wears', 26),\n",
              "             ('hunks', 52),\n",
              "             ('orders', 26),\n",
              "             ('broom', 26),\n",
              "             ('sweep', 52),\n",
              "             ('decks', 26),\n",
              "             ('indignity', 26),\n",
              "             ('amount', 26),\n",
              "             ('weighed', 52),\n",
              "             ('scales', 26),\n",
              "             ('new', 286),\n",
              "             ('testament', 26),\n",
              "             ('think', 182),\n",
              "             ('archangel', 26),\n",
              "             ('gabriel', 26),\n",
              "             ('thinks', 182),\n",
              "             ('anything', 52),\n",
              "             ('less', 52),\n",
              "             ('promptly', 26),\n",
              "             ('obey', 26),\n",
              "             ('instance', 26),\n",
              "             ('ai', 104),\n",
              "             (\"n't\", 624),\n",
              "             ('slave', 26),\n",
              "             ('well', 208),\n",
              "             ('however', 208),\n",
              "             ('captains', 26),\n",
              "             ('thump', 52),\n",
              "             ('punch', 26),\n",
              "             ('satisfaction', 26),\n",
              "             ('knowing', 78),\n",
              "             ('everybody', 26),\n",
              "             ('else', 208),\n",
              "             ('served', 26),\n",
              "             ('either', 78),\n",
              "             ('physical', 26),\n",
              "             ('point', 52),\n",
              "             ('view', 52),\n",
              "             ('so', 1066),\n",
              "             ('universal', 26),\n",
              "             ('passed', 78),\n",
              "             ('hands', 78),\n",
              "             ('rub', 26),\n",
              "             ('shoulder', 26),\n",
              "             ('blades', 26),\n",
              "             ('again', 286),\n",
              "             ('always', 104),\n",
              "             ('paying', 78),\n",
              "             ('trouble', 26),\n",
              "             ('whereas', 26),\n",
              "             ('pay', 78),\n",
              "             ('single', 52),\n",
              "             ('penny', 78),\n",
              "             ('heard', 208),\n",
              "             ('contrary', 26),\n",
              "             ('difference', 52),\n",
              "             ('between', 234),\n",
              "             ('paid', 26),\n",
              "             ('act', 52),\n",
              "             ('perhaps', 130),\n",
              "             ('uncomfortable', 52),\n",
              "             ('infliction', 26),\n",
              "             ('orchard', 26),\n",
              "             ('thieves', 26),\n",
              "             ('entailed', 26),\n",
              "             ('us', 104),\n",
              "             ('paid,--what', 26),\n",
              "             ('compare', 52),\n",
              "             ('urbane', 26),\n",
              "             ('activity', 26),\n",
              "             ('receives', 26),\n",
              "             ('really', 104),\n",
              "             ('marvellous', 104),\n",
              "             ('considering', 26),\n",
              "             ('earnestly', 26),\n",
              "             ('believe', 26),\n",
              "             ('root', 26),\n",
              "             ('earthly', 52),\n",
              "             ('ills', 26),\n",
              "             ('monied', 26),\n",
              "             ('enter', 52),\n",
              "             ('heaven', 104),\n",
              "             ('ah', 26),\n",
              "             ('cheerfully', 26),\n",
              "             ('consign', 26),\n",
              "             ('perdition', 26),\n",
              "             ('finally', 26),\n",
              "             ('wholesome', 26),\n",
              "             ('exercise', 26),\n",
              "             ('pure', 26),\n",
              "             ('air', 104),\n",
              "             ('fore', 26),\n",
              "             ('castle', 26),\n",
              "             ('deck', 52),\n",
              "             ('far', 104),\n",
              "             ('prevalent', 26),\n",
              "             ('astern', 26),\n",
              "             ('violate', 26),\n",
              "             ('pythagorean', 26),\n",
              "             ('maxim', 26),\n",
              "             ('quarter', 52),\n",
              "             ('gets', 26),\n",
              "             ('atmosphere', 26),\n",
              "             ('second', 104),\n",
              "             ('sailors', 78),\n",
              "             ('breathes', 26),\n",
              "             ('commonalty', 26),\n",
              "             ('leaders', 52),\n",
              "             ('many', 104),\n",
              "             ('things', 130),\n",
              "             ('suspect', 26),\n",
              "             ('wherefore', 26),\n",
              "             ('after', 234),\n",
              "             ('repeatedly', 26),\n",
              "             ('smelt', 52),\n",
              "             ('merchant', 26),\n",
              "             ('whaling', 234),\n",
              "             ('invisible', 26),\n",
              "             ('police', 26),\n",
              "             ('fates', 52),\n",
              "             ('has', 104),\n",
              "             ('constant', 26),\n",
              "             ('surveillance', 26),\n",
              "             ('secretly', 26),\n",
              "             ('dogs', 26),\n",
              "             ('influences', 26),\n",
              "             ('unaccountable', 104),\n",
              "             ('answer', 130),\n",
              "             ('doubtless', 52),\n",
              "             ('formed', 52),\n",
              "             ('grand', 104),\n",
              "             ('programme', 26),\n",
              "             ('providence', 26),\n",
              "             ('drawn', 26),\n",
              "             ('came', 286),\n",
              "             ('brief', 26),\n",
              "             ('interlude', 26),\n",
              "             ('solo', 26),\n",
              "             ('extensive', 26),\n",
              "             ('performances', 26),\n",
              "             ('bill', 26),\n",
              "             ('run', 52),\n",
              "             ('contested', 26),\n",
              "             ('election', 26),\n",
              "             ('presidency', 26),\n",
              "             ('united', 26),\n",
              "             ('states', 26),\n",
              "             ('bloody', 26),\n",
              "             ('battle', 26),\n",
              "             ('affghanistan', 26),\n",
              "             ('exactly', 78),\n",
              "             ('stage', 52),\n",
              "             ('managers', 26),\n",
              "             ('put', 208),\n",
              "             ('shabby', 52),\n",
              "             ('others', 52),\n",
              "             ('magnificent', 26),\n",
              "             ('parts', 130),\n",
              "             ('tragedies', 26),\n",
              "             ('short', 78),\n",
              "             ('easy', 78),\n",
              "             ('genteel', 26),\n",
              "             ('comedies', 26),\n",
              "             ('jolly', 104),\n",
              "             ('farces', 26),\n",
              "             ('recall', 26),\n",
              "             ('circumstances', 52),\n",
              "             ('springs', 26),\n",
              "             ('motives', 52),\n",
              "             ('cunningly', 26),\n",
              "             ('presented', 26),\n",
              "             ('various', 52),\n",
              "             ('disguises', 26),\n",
              "             ('induced', 26),\n",
              "             ('performing', 26),\n",
              "             ('cajoling', 26),\n",
              "             ('delusion', 26),\n",
              "             ('choice', 26),\n",
              "             ('resulting', 26),\n",
              "             ('unbiased', 26),\n",
              "             ('freewill', 26),\n",
              "             ('discriminating', 26),\n",
              "             ('judgment', 26),\n",
              "             ('overwhelming', 26),\n",
              "             ('idea', 182),\n",
              "             ('whale', 260),\n",
              "             ('portentous', 78),\n",
              "             ('mysterious', 52),\n",
              "             ('monster', 26),\n",
              "             ('roused', 26),\n",
              "             ('curiosity', 52),\n",
              "             ('wild', 130),\n",
              "             ('seas', 156),\n",
              "             ('rolled', 156),\n",
              "             ('island', 78),\n",
              "             ('bulk', 26),\n",
              "             ('undeliverable', 26),\n",
              "             ('nameless', 78),\n",
              "             ('perils', 26),\n",
              "             ('attending', 26),\n",
              "             ('marvels', 26),\n",
              "             ('patagonian', 26),\n",
              "             ('sights', 26),\n",
              "             ('sounds', 78),\n",
              "             ('helped', 26),\n",
              "             ('sway', 26),\n",
              "             ('wish', 26),\n",
              "             ('inducements', 26),\n",
              "             ('tormented', 52),\n",
              "             ('everlasting', 52),\n",
              "             ('itch', 26),\n",
              "             ('remote', 26),\n",
              "             ('love', 26),\n",
              "             ('forbidden', 26),\n",
              "             ('barbarous', 26),\n",
              "             ('coasts', 26),\n",
              "             ('ignoring', 26),\n",
              "             ('good', 442),\n",
              "             ('quick', 26),\n",
              "             ('perceive', 26),\n",
              "             ('horror', 26),\n",
              "             ('social', 26),\n",
              "             ('since', 78),\n",
              "             ('friendly', 26),\n",
              "             ('terms', 26),\n",
              "             ('inmates', 26),\n",
              "             ('place', 390),\n",
              "             ('lodges', 26),\n",
              "             ('reason', 130),\n",
              "             ('welcome', 26),\n",
              "             ('flood', 26),\n",
              "             ('gates', 26),\n",
              "             ('wonder', 52),\n",
              "             ('swung', 26),\n",
              "             ('open', 104),\n",
              "             ('conceits', 26),\n",
              "             ('swayed', 26),\n",
              "             ('purpose', 52),\n",
              "             ('floated', 52),\n",
              "             ('inmost', 26),\n",
              "             ('endless', 26),\n",
              "             ('processions', 26),\n",
              "             ('mid', 26),\n",
              "             ('hooded', 26),\n",
              "             ('snow', 78),\n",
              "             ('stuffed', 52),\n",
              "             ('shirt', 104),\n",
              "             ('carpet', 26),\n",
              "             ('bag', 182),\n",
              "             ('tucked', 26),\n",
              "             ('arm', 286),\n",
              "             ('started', 26),\n",
              "             ('cape', 104),\n",
              "             ('horn', 52),\n",
              "             ('pacific', 26),\n",
              "             ('quitting', 26),\n",
              "             ('manhatto', 26),\n",
              "             ('duly', 26),\n",
              "             ('arrived', 52),\n",
              "             ('bedford', 104),\n",
              "             ('saturday', 78),\n",
              "             ('night', 624),\n",
              "             ('december', 26),\n",
              "             ('disappointed', 26),\n",
              "             ('learning', 26),\n",
              "             ('packet', 26),\n",
              "             ('nantucket', 182),\n",
              "             ('had', 858),\n",
              "             ('already', 26),\n",
              "             ('sailed', 26),\n",
              "             ('offer', 52),\n",
              "             ('till', 156),\n",
              "             ('following', 52),\n",
              "             ('monday', 26),\n",
              "             ('young', 130),\n",
              "             ('candidates', 26),\n",
              "             ('pains', 26),\n",
              "             ('penalties', 26),\n",
              "             ('stop', 208),\n",
              "             ('embark', 52),\n",
              "             ('related', 26),\n",
              "             ('doing', 26),\n",
              "             ('made', 338),\n",
              "             ('craft', 130),\n",
              "             ('fine', 104),\n",
              "             ('boisterous', 26),\n",
              "             ('everything', 26),\n",
              "             ('connected', 26),\n",
              "             ('famous', 26),\n",
              "             ('amazingly', 26),\n",
              "             ('pleased', 52),\n",
              "             ('late', 182),\n",
              "             ('gradually', 26),\n",
              "             ('monopolising', 26),\n",
              "             ('business', 130),\n",
              "             ('matter', 78),\n",
              "             ('behind', 26),\n",
              "             ('original', 52),\n",
              "             ('tyre', 26),\n",
              "             ('carthage;--the', 26),\n",
              "             ('dead', 130),\n",
              "             ('stranded', 52),\n",
              "             ('aboriginal', 26),\n",
              "             ('whalemen', 26),\n",
              "             ('red', 78),\n",
              "             ('sally', 26),\n",
              "             ('canoes', 26),\n",
              "             ('chase', 26),\n",
              "             ('leviathan', 52),\n",
              "             ('too', 364),\n",
              "             ('adventurous', 26),\n",
              "             ('sloop', 26),\n",
              "             ('forth', 26),\n",
              "             ('partly', 78),\n",
              "             ('laden', 26),\n",
              "             ('imported', 26),\n",
              "             ('cobblestones', 26),\n",
              "             ('throw', 26),\n",
              "             ('whales', 52),\n",
              "             ('discover', 26),\n",
              "             ('risk', 26),\n",
              "             ('harpoon', 135),\n",
              "             ('bowsprit', 26),\n",
              "             ('day', 156),\n",
              "             ('another', 130),\n",
              "             ('ere', 78),\n",
              "             ('destined', 26),\n",
              "             ('port', 26),\n",
              "             ('became', 78),\n",
              "             ('concernment', 26),\n",
              "             ('eat', 26),\n",
              "             ('meanwhile', 78),\n",
              "             ('dubious', 26),\n",
              "             ('nay', 52),\n",
              "             ('dark', 208),\n",
              "             ('dismal', 52),\n",
              "             ('bitingly', 26),\n",
              "             ('cold', 182),\n",
              "             ('cheerless', 26),\n",
              "             ('anxious', 26),\n",
              "             ('grapnels', 26),\n",
              "             ('sounded', 26),\n",
              "             ('pocket', 78),\n",
              "             ('only', 364),\n",
              "             ('brought', 26),\n",
              "             ('pieces', 26),\n",
              "             ('silver,--so', 26),\n",
              "             ('wherever', 52),\n",
              "             ('said', 494),\n",
              "             ('stood', 260),\n",
              "             ('middle', 130),\n",
              "             ('dreary', 52),\n",
              "             ('shouldering', 26),\n",
              "             ('comparing', 26),\n",
              "             ('gloom', 26),\n",
              "             ('darkness', 78),\n",
              "             ('wisdom', 26),\n",
              "             ('conclude', 26),\n",
              "             ('lodge', 26),\n",
              "             ('dear', 26),\n",
              "             ('sure', 130),\n",
              "             ('inquire', 26),\n",
              "             ('price', 26),\n",
              "             ('halting', 26),\n",
              "             ('steps', 26),\n",
              "             ('paced', 26),\n",
              "             ('sign', 156),\n",
              "             ('crossed', 52),\n",
              "             ('harpoons\"--but', 26),\n",
              "             ('looked', 156),\n",
              "             ('expensive', 52),\n",
              "             ('further', 104),\n",
              "             ('bright', 52),\n",
              "             ('windows', 52),\n",
              "             ('fish', 78),\n",
              "             ('inn', 78),\n",
              "             ('fervent', 26),\n",
              "             ('rays', 26),\n",
              "             ('seemed', 416),\n",
              "             ('melted', 26),\n",
              "             ('packed', 52),\n",
              "             ('ice', 104),\n",
              "             ('house', 286),\n",
              "             ('everywhere', 26),\n",
              "             ('congealed', 26),\n",
              "             ('frost', 104),\n",
              "             ('lay', 234),\n",
              "             ('inches', 52),\n",
              "             ('thick', 52),\n",
              "             ...])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "900188d6",
        "outputId": "73e06bcd-32e6-4da4-aa28-b66c0d75f478"
      },
      "source": [
        "len(tokenizer.word_counts)"
      ],
      "id": "900188d6",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03b5f920"
      },
      "source": [
        "vocabulary_size=len(tokenizer.index_word)"
      ],
      "id": "03b5f920",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f776e37",
        "outputId": "e50f7393-f36e-4d90-852f-203ac892593d"
      },
      "source": [
        "vocabulary_size"
      ],
      "id": "8f776e37",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af3803da",
        "outputId": "635f803d-b377-47b3-b1bf-b0acfb705bcd"
      },
      "source": [
        "type(sequences)"
      ],
      "id": "af3803da",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58911a92"
      },
      "source": [
        "**Sequences data type to numpy array**"
      ],
      "id": "58911a92"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be265ed2"
      },
      "source": [
        "sequences=np.array(sequences)"
      ],
      "id": "be265ed2",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14269e2c",
        "outputId": "34cde97b-1d43-466d-9149-e55b0da0e915"
      },
      "source": [
        "sequences[0:3]"
      ],
      "id": "14269e2c",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   14,  263,   51,  261,  408,   87,  219,  129,  111,  954,\n",
              "         260,   50,   43,   38,  315,    7,   23,  546,    3,  150,  259,\n",
              "           6, 2712,   14,   24],\n",
              "       [  14,  263,   51,  261,  408,   87,  219,  129,  111,  954,  260,\n",
              "          50,   43,   38,  315,    7,   23,  546,    3,  150,  259,    6,\n",
              "        2712,   14,   24,  957],\n",
              "       [ 263,   51,  261,  408,   87,  219,  129,  111,  954,  260,   50,\n",
              "          43,   38,  315,    7,   23,  546,    3,  150,  259,    6, 2712,\n",
              "          14,   24,  957,    5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45d2ed9",
        "outputId": "29c58011-b1de-4b5d-f996-5e926a423300"
      },
      "source": [
        "type(sequences)"
      ],
      "id": "e45d2ed9",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8712b5c"
      },
      "source": [
        "## Now let's split the data into features and labels"
      ],
      "id": "a8712b5c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb5fe879",
        "outputId": "c1575e56-3f39-4cb9-dba4-1621c012f26a"
      },
      "source": [
        "sequences[:,:-1][:4]"
      ],
      "id": "fb5fe879",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   14,  263,   51,  261,  408,   87,  219,  129,  111,  954,\n",
              "         260,   50,   43,   38,  315,    7,   23,  546,    3,  150,  259,\n",
              "           6, 2712,   14],\n",
              "       [  14,  263,   51,  261,  408,   87,  219,  129,  111,  954,  260,\n",
              "          50,   43,   38,  315,    7,   23,  546,    3,  150,  259,    6,\n",
              "        2712,   14,   24],\n",
              "       [ 263,   51,  261,  408,   87,  219,  129,  111,  954,  260,   50,\n",
              "          43,   38,  315,    7,   23,  546,    3,  150,  259,    6, 2712,\n",
              "          14,   24,  957],\n",
              "       [  51,  261,  408,   87,  219,  129,  111,  954,  260,   50,   43,\n",
              "          38,  315,    7,   23,  546,    3,  150,  259,    6, 2712,   14,\n",
              "          24,  957,    5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32cc6fd",
        "outputId": "7f3803d5-1f4a-4749-ddea-0a8df6b4a013"
      },
      "source": [
        "sequences[:,-1][:4]"
      ],
      "id": "d32cc6fd",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 24, 957,   5,  60])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08af53d9"
      },
      "source": [
        "X=sequences[:,:-1]\n",
        "y=sequences[:,-1]"
      ],
      "id": "08af53d9",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "983e77f7"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "id": "983e77f7",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bd770ba"
      },
      "source": [
        "y=to_categorical(y,num_classes=vocabulary_size+1)"
      ],
      "id": "9bd770ba",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62bf21ac"
      },
      "source": [
        "seq_len=X.shape[1]"
      ],
      "id": "62bf21ac",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fd09f40",
        "outputId": "e51560d9-9e95-435a-aebf-689d2eabd883"
      },
      "source": [
        "y.shape"
      ],
      "id": "0fd09f40",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11312, 2718)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "515831da",
        "outputId": "34965fa4-2893-4b61-9aa3-2fe0564dde9e"
      },
      "source": [
        "seq_len"
      ],
      "id": "515831da",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28c04c37",
        "outputId": "dd0ff04d-b4c6-484d-be40-9a45468cbc06"
      },
      "source": [
        "X.shape"
      ],
      "id": "28c04c37",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11312, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2bd6408"
      },
      "source": [
        "## Build a model"
      ],
      "id": "f2bd6408"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "318e3d12"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding,Dropout"
      ],
      "id": "318e3d12",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "167fa0b7"
      },
      "source": [
        "# create a function for our model\n",
        "def create_model(vocabulary_size,seq_len):\n",
        "    model=Sequential()\n",
        "    model.add(Embedding(vocabulary_size,seq_len,input_length=seq_len))\n",
        "    model.add(LSTM(250,return_sequences=True))\n",
        "    model.add(Dropout(0.35))\n",
        "    model.add(LSTM(250))\n",
        "    model.add(Dropout(0.35))\n",
        "    model.add(Dense(150,activation='relu'))\n",
        "    model.add(Dense(vocabulary_size,activation=\"softmax\"))\n",
        "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "id": "167fa0b7",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6468fc76",
        "outputId": "1c9a4c4d-9c08-472e-a375-67a8254155b0"
      },
      "source": [
        "model=create_model(vocabulary_size+1,seq_len)"
      ],
      "id": "6468fc76",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 25)            67950     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 25, 250)           276000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25, 250)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 250)               501000    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 150)               37650     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2718)              410418    \n",
            "=================================================================\n",
            "Total params: 1,293,018\n",
            "Trainable params: 1,293,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a96fe314"
      },
      "source": [
        "## Train the model"
      ],
      "id": "a96fe314"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cedd2887",
        "outputId": "797c4f7d-755c-449b-8907-463b7aae10a2"
      },
      "source": [
        "model.fit(X,y,batch_size=32,epochs=350,verbose=2)"
      ],
      "id": "cedd2887",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "354/354 - 27s - loss: 6.6345 - accuracy: 0.0480\n",
            "Epoch 2/350\n",
            "354/354 - 3s - loss: 6.2764 - accuracy: 0.0529\n",
            "Epoch 3/350\n",
            "354/354 - 3s - loss: 6.1677 - accuracy: 0.0526\n",
            "Epoch 4/350\n",
            "354/354 - 3s - loss: 6.0687 - accuracy: 0.0617\n",
            "Epoch 5/350\n",
            "354/354 - 3s - loss: 5.9275 - accuracy: 0.0655\n",
            "Epoch 6/350\n",
            "354/354 - 3s - loss: 5.8148 - accuracy: 0.0679\n",
            "Epoch 7/350\n",
            "354/354 - 3s - loss: 5.9010 - accuracy: 0.0650\n",
            "Epoch 8/350\n",
            "354/354 - 3s - loss: 5.7382 - accuracy: 0.0677\n",
            "Epoch 9/350\n",
            "354/354 - 3s - loss: 5.6463 - accuracy: 0.0706\n",
            "Epoch 10/350\n",
            "354/354 - 3s - loss: 5.5677 - accuracy: 0.0723\n",
            "Epoch 11/350\n",
            "354/354 - 3s - loss: 5.4936 - accuracy: 0.0728\n",
            "Epoch 12/350\n",
            "354/354 - 3s - loss: 5.4125 - accuracy: 0.0753\n",
            "Epoch 13/350\n",
            "354/354 - 3s - loss: 5.3375 - accuracy: 0.0769\n",
            "Epoch 14/350\n",
            "354/354 - 3s - loss: 5.2685 - accuracy: 0.0773\n",
            "Epoch 15/350\n",
            "354/354 - 3s - loss: 5.1950 - accuracy: 0.0794\n",
            "Epoch 16/350\n",
            "354/354 - 3s - loss: 5.1218 - accuracy: 0.0829\n",
            "Epoch 17/350\n",
            "354/354 - 3s - loss: 5.0618 - accuracy: 0.0853\n",
            "Epoch 18/350\n",
            "354/354 - 3s - loss: 4.9978 - accuracy: 0.0855\n",
            "Epoch 19/350\n",
            "354/354 - 3s - loss: 4.9395 - accuracy: 0.0885\n",
            "Epoch 20/350\n",
            "354/354 - 3s - loss: 4.8846 - accuracy: 0.0888\n",
            "Epoch 21/350\n",
            "354/354 - 3s - loss: 4.8250 - accuracy: 0.0904\n",
            "Epoch 22/350\n",
            "354/354 - 3s - loss: 4.7633 - accuracy: 0.0916\n",
            "Epoch 23/350\n",
            "354/354 - 3s - loss: 4.7774 - accuracy: 0.0933\n",
            "Epoch 24/350\n",
            "354/354 - 3s - loss: 4.6961 - accuracy: 0.0952\n",
            "Epoch 25/350\n",
            "354/354 - 3s - loss: 4.6223 - accuracy: 0.0962\n",
            "Epoch 26/350\n",
            "354/354 - 3s - loss: 4.5702 - accuracy: 0.0961\n",
            "Epoch 27/350\n",
            "354/354 - 3s - loss: 4.5639 - accuracy: 0.0979\n",
            "Epoch 28/350\n",
            "354/354 - 3s - loss: 4.5756 - accuracy: 0.0992\n",
            "Epoch 29/350\n",
            "354/354 - 3s - loss: 4.5111 - accuracy: 0.1025\n",
            "Epoch 30/350\n",
            "354/354 - 3s - loss: 4.4959 - accuracy: 0.1014\n",
            "Epoch 31/350\n",
            "354/354 - 3s - loss: 4.4395 - accuracy: 0.1048\n",
            "Epoch 32/350\n",
            "354/354 - 3s - loss: 4.3655 - accuracy: 0.1091\n",
            "Epoch 33/350\n",
            "354/354 - 3s - loss: 4.2662 - accuracy: 0.1089\n",
            "Epoch 34/350\n",
            "354/354 - 3s - loss: 4.1966 - accuracy: 0.1133\n",
            "Epoch 35/350\n",
            "354/354 - 3s - loss: 4.1630 - accuracy: 0.1146\n",
            "Epoch 36/350\n",
            "354/354 - 3s - loss: 4.2333 - accuracy: 0.1149\n",
            "Epoch 37/350\n",
            "354/354 - 3s - loss: 4.2190 - accuracy: 0.1103\n",
            "Epoch 38/350\n",
            "354/354 - 3s - loss: 4.1109 - accuracy: 0.1189\n",
            "Epoch 39/350\n",
            "354/354 - 3s - loss: 4.0326 - accuracy: 0.1231\n",
            "Epoch 40/350\n",
            "354/354 - 3s - loss: 3.9446 - accuracy: 0.1260\n",
            "Epoch 41/350\n",
            "354/354 - 3s - loss: 3.9858 - accuracy: 0.1272\n",
            "Epoch 42/350\n",
            "354/354 - 3s - loss: 4.0672 - accuracy: 0.1199\n",
            "Epoch 43/350\n",
            "354/354 - 3s - loss: 4.0115 - accuracy: 0.1196\n",
            "Epoch 44/350\n",
            "354/354 - 3s - loss: 3.9209 - accuracy: 0.1295\n",
            "Epoch 45/350\n",
            "354/354 - 3s - loss: 3.8082 - accuracy: 0.1362\n",
            "Epoch 46/350\n",
            "354/354 - 3s - loss: 3.7568 - accuracy: 0.1406\n",
            "Epoch 47/350\n",
            "354/354 - 3s - loss: 3.7078 - accuracy: 0.1472\n",
            "Epoch 48/350\n",
            "354/354 - 3s - loss: 3.6351 - accuracy: 0.1537\n",
            "Epoch 49/350\n",
            "354/354 - 3s - loss: 3.5848 - accuracy: 0.1604\n",
            "Epoch 50/350\n",
            "354/354 - 3s - loss: 3.5223 - accuracy: 0.1657\n",
            "Epoch 51/350\n",
            "354/354 - 3s - loss: 3.4918 - accuracy: 0.1675\n",
            "Epoch 52/350\n",
            "354/354 - 3s - loss: 3.4371 - accuracy: 0.1790\n",
            "Epoch 53/350\n",
            "354/354 - 3s - loss: 3.4015 - accuracy: 0.1805\n",
            "Epoch 54/350\n",
            "354/354 - 3s - loss: 3.3626 - accuracy: 0.1900\n",
            "Epoch 55/350\n",
            "354/354 - 3s - loss: 3.3008 - accuracy: 0.1957\n",
            "Epoch 56/350\n",
            "354/354 - 3s - loss: 3.2784 - accuracy: 0.1949\n",
            "Epoch 57/350\n",
            "354/354 - 3s - loss: 3.2258 - accuracy: 0.2012\n",
            "Epoch 58/350\n",
            "354/354 - 3s - loss: 3.1680 - accuracy: 0.2152\n",
            "Epoch 59/350\n",
            "354/354 - 3s - loss: 3.1554 - accuracy: 0.2200\n",
            "Epoch 60/350\n",
            "354/354 - 3s - loss: 3.1538 - accuracy: 0.2168\n",
            "Epoch 61/350\n",
            "354/354 - 3s - loss: 3.1299 - accuracy: 0.2196\n",
            "Epoch 62/350\n",
            "354/354 - 3s - loss: 3.0744 - accuracy: 0.2306\n",
            "Epoch 63/350\n",
            "354/354 - 3s - loss: 3.0623 - accuracy: 0.2290\n",
            "Epoch 64/350\n",
            "354/354 - 3s - loss: 3.0039 - accuracy: 0.2358\n",
            "Epoch 65/350\n",
            "354/354 - 3s - loss: 2.9738 - accuracy: 0.2463\n",
            "Epoch 66/350\n",
            "354/354 - 3s - loss: 2.9308 - accuracy: 0.2527\n",
            "Epoch 67/350\n",
            "354/354 - 3s - loss: 2.8911 - accuracy: 0.2591\n",
            "Epoch 68/350\n",
            "354/354 - 3s - loss: 2.9107 - accuracy: 0.2565\n",
            "Epoch 69/350\n",
            "354/354 - 3s - loss: 2.8728 - accuracy: 0.2564\n",
            "Epoch 70/350\n",
            "354/354 - 3s - loss: 2.9313 - accuracy: 0.2565\n",
            "Epoch 71/350\n",
            "354/354 - 3s - loss: 2.8421 - accuracy: 0.2712\n",
            "Epoch 72/350\n",
            "354/354 - 3s - loss: 2.8505 - accuracy: 0.2734\n",
            "Epoch 73/350\n",
            "354/354 - 3s - loss: 2.8151 - accuracy: 0.2750\n",
            "Epoch 74/350\n",
            "354/354 - 3s - loss: 2.7430 - accuracy: 0.2861\n",
            "Epoch 75/350\n",
            "354/354 - 3s - loss: 2.6837 - accuracy: 0.2976\n",
            "Epoch 76/350\n",
            "354/354 - 3s - loss: 2.6999 - accuracy: 0.2951\n",
            "Epoch 77/350\n",
            "354/354 - 3s - loss: 2.7275 - accuracy: 0.3012\n",
            "Epoch 78/350\n",
            "354/354 - 3s - loss: 2.9426 - accuracy: 0.2600\n",
            "Epoch 79/350\n",
            "354/354 - 3s - loss: 2.8696 - accuracy: 0.2708\n",
            "Epoch 80/350\n",
            "354/354 - 3s - loss: 2.8353 - accuracy: 0.2732\n",
            "Epoch 81/350\n",
            "354/354 - 3s - loss: 2.7717 - accuracy: 0.2799\n",
            "Epoch 82/350\n",
            "354/354 - 3s - loss: 2.7331 - accuracy: 0.2794\n",
            "Epoch 83/350\n",
            "354/354 - 3s - loss: 2.6736 - accuracy: 0.2944\n",
            "Epoch 84/350\n",
            "354/354 - 3s - loss: 2.6366 - accuracy: 0.3051\n",
            "Epoch 85/350\n",
            "354/354 - 3s - loss: 2.6107 - accuracy: 0.3067\n",
            "Epoch 86/350\n",
            "354/354 - 3s - loss: 2.5582 - accuracy: 0.3152\n",
            "Epoch 87/350\n",
            "354/354 - 3s - loss: 2.5346 - accuracy: 0.3300\n",
            "Epoch 88/350\n",
            "354/354 - 3s - loss: 2.4836 - accuracy: 0.3378\n",
            "Epoch 89/350\n",
            "354/354 - 3s - loss: 2.4575 - accuracy: 0.3449\n",
            "Epoch 90/350\n",
            "354/354 - 3s - loss: 2.4066 - accuracy: 0.3571\n",
            "Epoch 91/350\n",
            "354/354 - 3s - loss: 2.3742 - accuracy: 0.3551\n",
            "Epoch 92/350\n",
            "354/354 - 3s - loss: 2.3464 - accuracy: 0.3686\n",
            "Epoch 93/350\n",
            "354/354 - 3s - loss: 2.3118 - accuracy: 0.3691\n",
            "Epoch 94/350\n",
            "354/354 - 3s - loss: 2.2742 - accuracy: 0.3774\n",
            "Epoch 95/350\n",
            "354/354 - 3s - loss: 2.2476 - accuracy: 0.3854\n",
            "Epoch 96/350\n",
            "354/354 - 3s - loss: 2.2106 - accuracy: 0.3876\n",
            "Epoch 97/350\n",
            "354/354 - 3s - loss: 2.1833 - accuracy: 0.4006\n",
            "Epoch 98/350\n",
            "354/354 - 3s - loss: 2.1606 - accuracy: 0.4048\n",
            "Epoch 99/350\n",
            "354/354 - 3s - loss: 2.1366 - accuracy: 0.4122\n",
            "Epoch 100/350\n",
            "354/354 - 3s - loss: 2.0991 - accuracy: 0.4123\n",
            "Epoch 101/350\n",
            "354/354 - 3s - loss: 2.0983 - accuracy: 0.4165\n",
            "Epoch 102/350\n",
            "354/354 - 3s - loss: 2.0470 - accuracy: 0.4371\n",
            "Epoch 103/350\n",
            "354/354 - 3s - loss: 2.0247 - accuracy: 0.4281\n",
            "Epoch 104/350\n",
            "354/354 - 3s - loss: 1.9911 - accuracy: 0.4386\n",
            "Epoch 105/350\n",
            "354/354 - 3s - loss: 1.9707 - accuracy: 0.4443\n",
            "Epoch 106/350\n",
            "354/354 - 3s - loss: 1.9297 - accuracy: 0.4511\n",
            "Epoch 107/350\n",
            "354/354 - 3s - loss: 1.9364 - accuracy: 0.4554\n",
            "Epoch 108/350\n",
            "354/354 - 3s - loss: 1.8923 - accuracy: 0.4617\n",
            "Epoch 109/350\n",
            "354/354 - 3s - loss: 1.8645 - accuracy: 0.4702\n",
            "Epoch 110/350\n",
            "354/354 - 3s - loss: 1.8329 - accuracy: 0.4780\n",
            "Epoch 111/350\n",
            "354/354 - 3s - loss: 1.7951 - accuracy: 0.4867\n",
            "Epoch 112/350\n",
            "354/354 - 3s - loss: 1.7834 - accuracy: 0.4920\n",
            "Epoch 113/350\n",
            "354/354 - 3s - loss: 1.7497 - accuracy: 0.5014\n",
            "Epoch 114/350\n",
            "354/354 - 3s - loss: 1.7617 - accuracy: 0.4895\n",
            "Epoch 115/350\n",
            "354/354 - 3s - loss: 1.7247 - accuracy: 0.5007\n",
            "Epoch 116/350\n",
            "354/354 - 3s - loss: 1.7120 - accuracy: 0.5048\n",
            "Epoch 117/350\n",
            "354/354 - 3s - loss: 1.6517 - accuracy: 0.5188\n",
            "Epoch 118/350\n",
            "354/354 - 3s - loss: 1.6381 - accuracy: 0.5187\n",
            "Epoch 119/350\n",
            "354/354 - 3s - loss: 1.6366 - accuracy: 0.5223\n",
            "Epoch 120/350\n",
            "354/354 - 3s - loss: 1.5881 - accuracy: 0.5377\n",
            "Epoch 121/350\n",
            "354/354 - 3s - loss: 1.5649 - accuracy: 0.5439\n",
            "Epoch 122/350\n",
            "354/354 - 3s - loss: 1.5731 - accuracy: 0.5400\n",
            "Epoch 123/350\n",
            "354/354 - 3s - loss: 1.5364 - accuracy: 0.5499\n",
            "Epoch 124/350\n",
            "354/354 - 3s - loss: 1.5201 - accuracy: 0.5526\n",
            "Epoch 125/350\n",
            "354/354 - 3s - loss: 1.5115 - accuracy: 0.5537\n",
            "Epoch 126/350\n",
            "354/354 - 3s - loss: 1.5006 - accuracy: 0.5596\n",
            "Epoch 127/350\n",
            "354/354 - 3s - loss: 1.4783 - accuracy: 0.5602\n",
            "Epoch 128/350\n",
            "354/354 - 3s - loss: 1.4762 - accuracy: 0.5636\n",
            "Epoch 129/350\n",
            "354/354 - 3s - loss: 1.4572 - accuracy: 0.5712\n",
            "Epoch 130/350\n",
            "354/354 - 3s - loss: 1.4406 - accuracy: 0.5749\n",
            "Epoch 131/350\n",
            "354/354 - 3s - loss: 1.4265 - accuracy: 0.5736\n",
            "Epoch 132/350\n",
            "354/354 - 3s - loss: 1.3832 - accuracy: 0.5904\n",
            "Epoch 133/350\n",
            "354/354 - 3s - loss: 1.3582 - accuracy: 0.5988\n",
            "Epoch 134/350\n",
            "354/354 - 3s - loss: 1.3398 - accuracy: 0.6020\n",
            "Epoch 135/350\n",
            "354/354 - 3s - loss: 1.3241 - accuracy: 0.6070\n",
            "Epoch 136/350\n",
            "354/354 - 3s - loss: 1.3091 - accuracy: 0.6101\n",
            "Epoch 137/350\n",
            "354/354 - 3s - loss: 1.3079 - accuracy: 0.6063\n",
            "Epoch 138/350\n",
            "354/354 - 3s - loss: 1.2718 - accuracy: 0.6180\n",
            "Epoch 139/350\n",
            "354/354 - 3s - loss: 1.2629 - accuracy: 0.6267\n",
            "Epoch 140/350\n",
            "354/354 - 3s - loss: 1.2362 - accuracy: 0.6305\n",
            "Epoch 141/350\n",
            "354/354 - 3s - loss: 1.2464 - accuracy: 0.6227\n",
            "Epoch 142/350\n",
            "354/354 - 3s - loss: 1.2110 - accuracy: 0.6385\n",
            "Epoch 143/350\n",
            "354/354 - 3s - loss: 1.1961 - accuracy: 0.6399\n",
            "Epoch 144/350\n",
            "354/354 - 3s - loss: 1.1755 - accuracy: 0.6433\n",
            "Epoch 145/350\n",
            "354/354 - 3s - loss: 1.2212 - accuracy: 0.6325\n",
            "Epoch 146/350\n",
            "354/354 - 3s - loss: 1.1781 - accuracy: 0.6447\n",
            "Epoch 147/350\n",
            "354/354 - 3s - loss: 1.1518 - accuracy: 0.6528\n",
            "Epoch 148/350\n",
            "354/354 - 3s - loss: 1.1280 - accuracy: 0.6616\n",
            "Epoch 149/350\n",
            "354/354 - 3s - loss: 1.1178 - accuracy: 0.6583\n",
            "Epoch 150/350\n",
            "354/354 - 3s - loss: 1.1100 - accuracy: 0.6607\n",
            "Epoch 151/350\n",
            "354/354 - 3s - loss: 1.1005 - accuracy: 0.6716\n",
            "Epoch 152/350\n",
            "354/354 - 3s - loss: 1.0789 - accuracy: 0.6659\n",
            "Epoch 153/350\n",
            "354/354 - 3s - loss: 1.0761 - accuracy: 0.6675\n",
            "Epoch 154/350\n",
            "354/354 - 3s - loss: 1.0535 - accuracy: 0.6858\n",
            "Epoch 155/350\n",
            "354/354 - 3s - loss: 1.0423 - accuracy: 0.6814\n",
            "Epoch 156/350\n",
            "354/354 - 3s - loss: 1.0481 - accuracy: 0.6842\n",
            "Epoch 157/350\n",
            "354/354 - 3s - loss: 1.0355 - accuracy: 0.6861\n",
            "Epoch 158/350\n",
            "354/354 - 3s - loss: 1.0028 - accuracy: 0.6947\n",
            "Epoch 159/350\n",
            "354/354 - 3s - loss: 1.0114 - accuracy: 0.6940\n",
            "Epoch 160/350\n",
            "354/354 - 3s - loss: 0.9823 - accuracy: 0.6997\n",
            "Epoch 161/350\n",
            "354/354 - 3s - loss: 0.9694 - accuracy: 0.7073\n",
            "Epoch 162/350\n",
            "354/354 - 3s - loss: 0.9693 - accuracy: 0.7045\n",
            "Epoch 163/350\n",
            "354/354 - 3s - loss: 0.9447 - accuracy: 0.7074\n",
            "Epoch 164/350\n",
            "354/354 - 3s - loss: 0.9440 - accuracy: 0.7130\n",
            "Epoch 165/350\n",
            "354/354 - 3s - loss: 0.9580 - accuracy: 0.7113\n",
            "Epoch 166/350\n",
            "354/354 - 3s - loss: 0.9165 - accuracy: 0.7187\n",
            "Epoch 167/350\n",
            "354/354 - 3s - loss: 0.9204 - accuracy: 0.7170\n",
            "Epoch 168/350\n",
            "354/354 - 3s - loss: 0.9132 - accuracy: 0.7196\n",
            "Epoch 169/350\n",
            "354/354 - 3s - loss: 0.8815 - accuracy: 0.7244\n",
            "Epoch 170/350\n",
            "354/354 - 3s - loss: 0.8957 - accuracy: 0.7264\n",
            "Epoch 171/350\n",
            "354/354 - 3s - loss: 0.9106 - accuracy: 0.7186\n",
            "Epoch 172/350\n",
            "354/354 - 3s - loss: 0.8697 - accuracy: 0.7291\n",
            "Epoch 173/350\n",
            "354/354 - 3s - loss: 0.8661 - accuracy: 0.7309\n",
            "Epoch 174/350\n",
            "354/354 - 3s - loss: 0.8540 - accuracy: 0.7315\n",
            "Epoch 175/350\n",
            "354/354 - 3s - loss: 0.8479 - accuracy: 0.7389\n",
            "Epoch 176/350\n",
            "354/354 - 3s - loss: 0.8328 - accuracy: 0.7479\n",
            "Epoch 177/350\n",
            "354/354 - 3s - loss: 0.8421 - accuracy: 0.7423\n",
            "Epoch 178/350\n",
            "354/354 - 3s - loss: 0.8084 - accuracy: 0.7522\n",
            "Epoch 179/350\n",
            "354/354 - 3s - loss: 0.8157 - accuracy: 0.7473\n",
            "Epoch 180/350\n",
            "354/354 - 3s - loss: 0.8134 - accuracy: 0.7469\n",
            "Epoch 181/350\n",
            "354/354 - 3s - loss: 0.8126 - accuracy: 0.7465\n",
            "Epoch 182/350\n",
            "354/354 - 3s - loss: 0.7702 - accuracy: 0.7626\n",
            "Epoch 183/350\n",
            "354/354 - 3s - loss: 0.7797 - accuracy: 0.7598\n",
            "Epoch 184/350\n",
            "354/354 - 3s - loss: 0.7782 - accuracy: 0.7578\n",
            "Epoch 185/350\n",
            "354/354 - 3s - loss: 0.7537 - accuracy: 0.7645\n",
            "Epoch 186/350\n",
            "354/354 - 3s - loss: 0.7663 - accuracy: 0.7633\n",
            "Epoch 187/350\n",
            "354/354 - 3s - loss: 0.7861 - accuracy: 0.7573\n",
            "Epoch 188/350\n",
            "354/354 - 3s - loss: 0.8234 - accuracy: 0.7588\n",
            "Epoch 189/350\n",
            "354/354 - 3s - loss: 0.7880 - accuracy: 0.7601\n",
            "Epoch 190/350\n",
            "354/354 - 3s - loss: 0.7378 - accuracy: 0.7770\n",
            "Epoch 191/350\n",
            "354/354 - 3s - loss: 0.7140 - accuracy: 0.7716\n",
            "Epoch 192/350\n",
            "354/354 - 3s - loss: 0.7162 - accuracy: 0.7777\n",
            "Epoch 193/350\n",
            "354/354 - 3s - loss: 0.7220 - accuracy: 0.7794\n",
            "Epoch 194/350\n",
            "354/354 - 3s - loss: 0.7101 - accuracy: 0.7784\n",
            "Epoch 195/350\n",
            "354/354 - 3s - loss: 0.7134 - accuracy: 0.7754\n",
            "Epoch 196/350\n",
            "354/354 - 3s - loss: 0.7308 - accuracy: 0.7740\n",
            "Epoch 197/350\n",
            "354/354 - 3s - loss: 0.7019 - accuracy: 0.7811\n",
            "Epoch 198/350\n",
            "354/354 - 3s - loss: 0.7067 - accuracy: 0.7856\n",
            "Epoch 199/350\n",
            "354/354 - 3s - loss: 0.6641 - accuracy: 0.7957\n",
            "Epoch 200/350\n",
            "354/354 - 3s - loss: 0.6842 - accuracy: 0.7920\n",
            "Epoch 201/350\n",
            "354/354 - 3s - loss: 0.6741 - accuracy: 0.7912\n",
            "Epoch 202/350\n",
            "354/354 - 3s - loss: 0.6885 - accuracy: 0.7897\n",
            "Epoch 203/350\n",
            "354/354 - 3s - loss: 0.6733 - accuracy: 0.7961\n",
            "Epoch 204/350\n",
            "354/354 - 3s - loss: 0.6544 - accuracy: 0.7977\n",
            "Epoch 205/350\n",
            "354/354 - 3s - loss: 0.6704 - accuracy: 0.7931\n",
            "Epoch 206/350\n",
            "354/354 - 3s - loss: 0.6570 - accuracy: 0.7906\n",
            "Epoch 207/350\n",
            "354/354 - 3s - loss: 0.6533 - accuracy: 0.7976\n",
            "Epoch 208/350\n",
            "354/354 - 3s - loss: 0.6505 - accuracy: 0.7982\n",
            "Epoch 209/350\n",
            "354/354 - 3s - loss: 0.6395 - accuracy: 0.8008\n",
            "Epoch 210/350\n",
            "354/354 - 3s - loss: 0.6411 - accuracy: 0.7977\n",
            "Epoch 211/350\n",
            "354/354 - 3s - loss: 0.6262 - accuracy: 0.8057\n",
            "Epoch 212/350\n",
            "354/354 - 3s - loss: 0.6139 - accuracy: 0.8091\n",
            "Epoch 213/350\n",
            "354/354 - 3s - loss: 0.6142 - accuracy: 0.8126\n",
            "Epoch 214/350\n",
            "354/354 - 3s - loss: 0.6023 - accuracy: 0.8135\n",
            "Epoch 215/350\n",
            "354/354 - 3s - loss: 0.6065 - accuracy: 0.8139\n",
            "Epoch 216/350\n",
            "354/354 - 3s - loss: 0.6115 - accuracy: 0.8125\n",
            "Epoch 217/350\n",
            "354/354 - 3s - loss: 0.6137 - accuracy: 0.8079\n",
            "Epoch 218/350\n",
            "354/354 - 3s - loss: 0.6100 - accuracy: 0.8093\n",
            "Epoch 219/350\n",
            "354/354 - 3s - loss: 0.6330 - accuracy: 0.8054\n",
            "Epoch 220/350\n",
            "354/354 - 3s - loss: 0.6057 - accuracy: 0.8129\n",
            "Epoch 221/350\n",
            "354/354 - 3s - loss: 0.5920 - accuracy: 0.8163\n",
            "Epoch 222/350\n",
            "354/354 - 3s - loss: 0.6183 - accuracy: 0.8133\n",
            "Epoch 223/350\n",
            "354/354 - 3s - loss: 0.6781 - accuracy: 0.8132\n",
            "Epoch 224/350\n",
            "354/354 - 3s - loss: 0.6721 - accuracy: 0.8094\n",
            "Epoch 225/350\n",
            "354/354 - 3s - loss: 0.6153 - accuracy: 0.8108\n",
            "Epoch 226/350\n",
            "354/354 - 3s - loss: 0.5967 - accuracy: 0.8191\n",
            "Epoch 227/350\n",
            "354/354 - 3s - loss: 0.5902 - accuracy: 0.8196\n",
            "Epoch 228/350\n",
            "354/354 - 3s - loss: 0.5819 - accuracy: 0.8253\n",
            "Epoch 229/350\n",
            "354/354 - 3s - loss: 0.5659 - accuracy: 0.8269\n",
            "Epoch 230/350\n",
            "354/354 - 3s - loss: 0.5678 - accuracy: 0.8293\n",
            "Epoch 231/350\n",
            "354/354 - 3s - loss: 0.5729 - accuracy: 0.8243\n",
            "Epoch 232/350\n",
            "354/354 - 3s - loss: 0.5828 - accuracy: 0.8246\n",
            "Epoch 233/350\n",
            "354/354 - 3s - loss: 0.5674 - accuracy: 0.8268\n",
            "Epoch 234/350\n",
            "354/354 - 3s - loss: 0.5523 - accuracy: 0.8294\n",
            "Epoch 235/350\n",
            "354/354 - 3s - loss: 0.5707 - accuracy: 0.8243\n",
            "Epoch 236/350\n",
            "354/354 - 3s - loss: 0.5681 - accuracy: 0.8254\n",
            "Epoch 237/350\n",
            "354/354 - 3s - loss: 0.5555 - accuracy: 0.8313\n",
            "Epoch 238/350\n",
            "354/354 - 3s - loss: 0.5566 - accuracy: 0.8297\n",
            "Epoch 239/350\n",
            "354/354 - 3s - loss: 0.5441 - accuracy: 0.8321\n",
            "Epoch 240/350\n",
            "354/354 - 3s - loss: 0.5412 - accuracy: 0.8322\n",
            "Epoch 241/350\n",
            "354/354 - 3s - loss: 0.5366 - accuracy: 0.8320\n",
            "Epoch 242/350\n",
            "354/354 - 3s - loss: 0.5334 - accuracy: 0.8332\n",
            "Epoch 243/350\n",
            "354/354 - 3s - loss: 0.5397 - accuracy: 0.8343\n",
            "Epoch 244/350\n",
            "354/354 - 3s - loss: 0.5018 - accuracy: 0.8431\n",
            "Epoch 245/350\n",
            "354/354 - 3s - loss: 0.5347 - accuracy: 0.8352\n",
            "Epoch 246/350\n",
            "354/354 - 3s - loss: 0.5167 - accuracy: 0.8396\n",
            "Epoch 247/350\n",
            "354/354 - 3s - loss: 0.4883 - accuracy: 0.8513\n",
            "Epoch 248/350\n",
            "354/354 - 3s - loss: 0.5184 - accuracy: 0.8400\n",
            "Epoch 249/350\n",
            "354/354 - 3s - loss: 0.5340 - accuracy: 0.8355\n",
            "Epoch 250/350\n",
            "354/354 - 3s - loss: 0.5496 - accuracy: 0.8312\n",
            "Epoch 251/350\n",
            "354/354 - 3s - loss: 0.5085 - accuracy: 0.8392\n",
            "Epoch 252/350\n",
            "354/354 - 3s - loss: 0.5139 - accuracy: 0.8436\n",
            "Epoch 253/350\n",
            "354/354 - 3s - loss: 0.4995 - accuracy: 0.8510\n",
            "Epoch 254/350\n",
            "354/354 - 3s - loss: 0.5033 - accuracy: 0.8440\n",
            "Epoch 255/350\n",
            "354/354 - 3s - loss: 0.5174 - accuracy: 0.8419\n",
            "Epoch 256/350\n",
            "354/354 - 3s - loss: 0.5067 - accuracy: 0.8461\n",
            "Epoch 257/350\n",
            "354/354 - 3s - loss: 0.4978 - accuracy: 0.8488\n",
            "Epoch 258/350\n",
            "354/354 - 3s - loss: 0.5055 - accuracy: 0.8463\n",
            "Epoch 259/350\n",
            "354/354 - 3s - loss: 0.5032 - accuracy: 0.8468\n",
            "Epoch 260/350\n",
            "354/354 - 3s - loss: 0.4926 - accuracy: 0.8442\n",
            "Epoch 261/350\n",
            "354/354 - 3s - loss: 0.4941 - accuracy: 0.8467\n",
            "Epoch 262/350\n",
            "354/354 - 3s - loss: 0.4890 - accuracy: 0.8491\n",
            "Epoch 263/350\n",
            "354/354 - 3s - loss: 0.4777 - accuracy: 0.8533\n",
            "Epoch 264/350\n",
            "354/354 - 3s - loss: 0.5071 - accuracy: 0.8457\n",
            "Epoch 265/350\n",
            "354/354 - 3s - loss: 0.5053 - accuracy: 0.8452\n",
            "Epoch 266/350\n",
            "354/354 - 3s - loss: 0.4760 - accuracy: 0.8575\n",
            "Epoch 267/350\n",
            "354/354 - 3s - loss: 0.4668 - accuracy: 0.8566\n",
            "Epoch 268/350\n",
            "354/354 - 3s - loss: 0.4875 - accuracy: 0.8521\n",
            "Epoch 269/350\n",
            "354/354 - 3s - loss: 0.4836 - accuracy: 0.8509\n",
            "Epoch 270/350\n",
            "354/354 - 3s - loss: 0.4752 - accuracy: 0.8560\n",
            "Epoch 271/350\n",
            "354/354 - 3s - loss: 0.4637 - accuracy: 0.8589\n",
            "Epoch 272/350\n",
            "354/354 - 3s - loss: 0.4393 - accuracy: 0.8647\n",
            "Epoch 273/350\n",
            "354/354 - 3s - loss: 0.4598 - accuracy: 0.8585\n",
            "Epoch 274/350\n",
            "354/354 - 3s - loss: 0.4448 - accuracy: 0.8609\n",
            "Epoch 275/350\n",
            "354/354 - 3s - loss: 0.4719 - accuracy: 0.8515\n",
            "Epoch 276/350\n",
            "354/354 - 3s - loss: 0.4548 - accuracy: 0.8586\n",
            "Epoch 277/350\n",
            "354/354 - 3s - loss: 0.4662 - accuracy: 0.8537\n",
            "Epoch 278/350\n",
            "354/354 - 3s - loss: 0.4602 - accuracy: 0.8574\n",
            "Epoch 279/350\n",
            "354/354 - 3s - loss: 0.4514 - accuracy: 0.8594\n",
            "Epoch 280/350\n",
            "354/354 - 3s - loss: 0.4735 - accuracy: 0.8579\n",
            "Epoch 281/350\n",
            "354/354 - 3s - loss: 0.4650 - accuracy: 0.8564\n",
            "Epoch 282/350\n",
            "354/354 - 3s - loss: 0.4801 - accuracy: 0.8487\n",
            "Epoch 283/350\n",
            "354/354 - 3s - loss: 0.4483 - accuracy: 0.8630\n",
            "Epoch 284/350\n",
            "354/354 - 3s - loss: 0.4346 - accuracy: 0.8673\n",
            "Epoch 285/350\n",
            "354/354 - 3s - loss: 0.4441 - accuracy: 0.8627\n",
            "Epoch 286/350\n",
            "354/354 - 3s - loss: 0.4353 - accuracy: 0.8632\n",
            "Epoch 287/350\n",
            "354/354 - 3s - loss: 0.4345 - accuracy: 0.8672\n",
            "Epoch 288/350\n",
            "354/354 - 3s - loss: 0.4243 - accuracy: 0.8716\n",
            "Epoch 289/350\n",
            "354/354 - 3s - loss: 0.4351 - accuracy: 0.8620\n",
            "Epoch 290/350\n",
            "354/354 - 3s - loss: 0.4335 - accuracy: 0.8667\n",
            "Epoch 291/350\n",
            "354/354 - 3s - loss: 0.4438 - accuracy: 0.8608\n",
            "Epoch 292/350\n",
            "354/354 - 3s - loss: 0.4327 - accuracy: 0.8647\n",
            "Epoch 293/350\n",
            "354/354 - 3s - loss: 0.4706 - accuracy: 0.8586\n",
            "Epoch 294/350\n",
            "354/354 - 3s - loss: 0.4497 - accuracy: 0.8640\n",
            "Epoch 295/350\n",
            "354/354 - 3s - loss: 0.4242 - accuracy: 0.8671\n",
            "Epoch 296/350\n",
            "354/354 - 3s - loss: 0.4233 - accuracy: 0.8709\n",
            "Epoch 297/350\n",
            "354/354 - 3s - loss: 0.4264 - accuracy: 0.8653\n",
            "Epoch 298/350\n",
            "354/354 - 3s - loss: 0.4532 - accuracy: 0.8567\n",
            "Epoch 299/350\n",
            "354/354 - 3s - loss: 0.4218 - accuracy: 0.8701\n",
            "Epoch 300/350\n",
            "354/354 - 3s - loss: 0.4282 - accuracy: 0.8678\n",
            "Epoch 301/350\n",
            "354/354 - 3s - loss: 0.3980 - accuracy: 0.8751\n",
            "Epoch 302/350\n",
            "354/354 - 3s - loss: 0.3882 - accuracy: 0.8792\n",
            "Epoch 303/350\n",
            "354/354 - 3s - loss: 0.4189 - accuracy: 0.8696\n",
            "Epoch 304/350\n",
            "354/354 - 3s - loss: 0.4352 - accuracy: 0.8685\n",
            "Epoch 305/350\n",
            "354/354 - 3s - loss: 0.4308 - accuracy: 0.8722\n",
            "Epoch 306/350\n",
            "354/354 - 3s - loss: 0.4328 - accuracy: 0.8710\n",
            "Epoch 307/350\n",
            "354/354 - 3s - loss: 0.4161 - accuracy: 0.8731\n",
            "Epoch 308/350\n",
            "354/354 - 3s - loss: 0.4253 - accuracy: 0.8692\n",
            "Epoch 309/350\n",
            "354/354 - 3s - loss: 0.4140 - accuracy: 0.8734\n",
            "Epoch 310/350\n",
            "354/354 - 3s - loss: 0.4260 - accuracy: 0.8706\n",
            "Epoch 311/350\n",
            "354/354 - 3s - loss: 0.4122 - accuracy: 0.8727\n",
            "Epoch 312/350\n",
            "354/354 - 3s - loss: 0.4205 - accuracy: 0.8707\n",
            "Epoch 313/350\n",
            "354/354 - 3s - loss: 0.4159 - accuracy: 0.8739\n",
            "Epoch 314/350\n",
            "354/354 - 3s - loss: 0.4089 - accuracy: 0.8801\n",
            "Epoch 315/350\n",
            "354/354 - 3s - loss: 0.3858 - accuracy: 0.8826\n",
            "Epoch 316/350\n",
            "354/354 - 3s - loss: 0.3951 - accuracy: 0.8767\n",
            "Epoch 317/350\n",
            "354/354 - 3s - loss: 0.4147 - accuracy: 0.8726\n",
            "Epoch 318/350\n",
            "354/354 - 3s - loss: 0.4149 - accuracy: 0.8738\n",
            "Epoch 319/350\n",
            "354/354 - 3s - loss: 0.4167 - accuracy: 0.8708\n",
            "Epoch 320/350\n",
            "354/354 - 3s - loss: 0.3760 - accuracy: 0.8798\n",
            "Epoch 321/350\n",
            "354/354 - 3s - loss: 0.3864 - accuracy: 0.8782\n",
            "Epoch 322/350\n",
            "354/354 - 3s - loss: 0.4081 - accuracy: 0.8773\n",
            "Epoch 323/350\n",
            "354/354 - 3s - loss: 0.3937 - accuracy: 0.8787\n",
            "Epoch 324/350\n",
            "354/354 - 3s - loss: 0.5159 - accuracy: 0.8694\n",
            "Epoch 325/350\n",
            "354/354 - 3s - loss: 0.5178 - accuracy: 0.8625\n",
            "Epoch 326/350\n",
            "354/354 - 3s - loss: 0.4217 - accuracy: 0.8777\n",
            "Epoch 327/350\n",
            "354/354 - 3s - loss: 0.4294 - accuracy: 0.8729\n",
            "Epoch 328/350\n",
            "354/354 - 3s - loss: 0.3863 - accuracy: 0.8822\n",
            "Epoch 329/350\n",
            "354/354 - 3s - loss: 0.3828 - accuracy: 0.8815\n",
            "Epoch 330/350\n",
            "354/354 - 3s - loss: 0.3984 - accuracy: 0.8808\n",
            "Epoch 331/350\n",
            "354/354 - 3s - loss: 0.3953 - accuracy: 0.8837\n",
            "Epoch 332/350\n",
            "354/354 - 3s - loss: 0.3944 - accuracy: 0.8772\n",
            "Epoch 333/350\n",
            "354/354 - 3s - loss: 0.3962 - accuracy: 0.8771\n",
            "Epoch 334/350\n",
            "354/354 - 3s - loss: 0.3951 - accuracy: 0.8779\n",
            "Epoch 335/350\n",
            "354/354 - 3s - loss: 0.3903 - accuracy: 0.8772\n",
            "Epoch 336/350\n",
            "354/354 - 3s - loss: 0.3935 - accuracy: 0.8786\n",
            "Epoch 337/350\n",
            "354/354 - 3s - loss: 0.3738 - accuracy: 0.8822\n",
            "Epoch 338/350\n",
            "354/354 - 3s - loss: 0.3742 - accuracy: 0.8831\n",
            "Epoch 339/350\n",
            "354/354 - 3s - loss: 0.3928 - accuracy: 0.8806\n",
            "Epoch 340/350\n",
            "354/354 - 3s - loss: 0.4039 - accuracy: 0.8790\n",
            "Epoch 341/350\n",
            "354/354 - 3s - loss: 0.3805 - accuracy: 0.8828\n",
            "Epoch 342/350\n",
            "354/354 - 3s - loss: 0.3902 - accuracy: 0.8785\n",
            "Epoch 343/350\n",
            "354/354 - 3s - loss: 0.3684 - accuracy: 0.8857\n",
            "Epoch 344/350\n",
            "354/354 - 3s - loss: 0.3631 - accuracy: 0.8875\n",
            "Epoch 345/350\n",
            "354/354 - 3s - loss: 0.3789 - accuracy: 0.8809\n",
            "Epoch 346/350\n",
            "354/354 - 3s - loss: 0.3826 - accuracy: 0.8824\n",
            "Epoch 347/350\n",
            "354/354 - 3s - loss: 0.3761 - accuracy: 0.8831\n",
            "Epoch 348/350\n",
            "354/354 - 3s - loss: 0.3810 - accuracy: 0.8830\n",
            "Epoch 349/350\n",
            "354/354 - 3s - loss: 0.3950 - accuracy: 0.8817\n",
            "Epoch 350/350\n",
            "354/354 - 3s - loss: 0.3786 - accuracy: 0.8869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bf0d83650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36b1f681"
      },
      "source": [
        "model.save(\"drive/MyDrive/Model/Text-Generation-Model-350.h5\")"
      ],
      "id": "36b1f681",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4nRGrAVNiG1"
      },
      "source": [
        "from pickle import load,dump\n",
        "dump(tokenizer, open('drive/MyDrive/Model/tokenizer', 'wb'))"
      ],
      "id": "f4nRGrAVNiG1",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izBVF_XNMswK"
      },
      "source": [
        "## Load the saved Model"
      ],
      "id": "izBVF_XNMswK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wleiBoUyGzT"
      },
      "source": [
        "from keras.models import load_model\n",
        "my_model=load_model('drive/MyDrive/Model/Text-Generation-Model-350.h5')"
      ],
      "id": "2wleiBoUyGzT",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f9tg04oMnUn"
      },
      "source": [
        "## Generating New Text"
      ],
      "id": "5f9tg04oMnUn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sge4tT2oOz6A"
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "id": "Sge4tT2oOz6A",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSyACSkIQV99"
      },
      "source": [
        "def gen_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "\n",
        "  '''\n",
        "    INPUTS:\n",
        "    model : model that was trained on text data\n",
        "    tokenizer : tokenizer that was fit on text data\n",
        "    seq_len : length of training sequence\n",
        "    seed_text : raw string text to serve as the seed\n",
        "    num_gen_words : number of words to be generated by model\n",
        "  '''\n",
        "  # Final Output\n",
        "  output_text=[]\n",
        "\n",
        "  # Initial Seed Sequence\n",
        "  input_text=seed_text\n",
        "\n",
        "  # Create num_gen_words\n",
        "  for i in range(num_gen_words):\n",
        "    #take in the input seed text and encode it to a sequence\n",
        "    encoded_text=tokenizer.texts_to_sequences([input_text])[0]\n",
        "\n",
        "    # pad sequences to our trained rate\n",
        "    pad_encoded=pad_sequences([encoded_text],maxlen=seq_len,truncating='pre')\n",
        "\n",
        "    # Predicting class Probabilities\n",
        "    predicted_index=model.predict_classes(pad_encoded,verbose=0)[0]\n",
        "\n",
        "    # grab the word \n",
        "    pred_word=tokenizer.index_word[predicted_index]\n",
        "\n",
        "    # Update the sequence of input text (shifting one over with the new word)\n",
        "    input_text=input_text+ \" \" + pred_word\n",
        "\n",
        "    #append the new word to output\n",
        "    output_text.append(pred_word)\n",
        "\n",
        "  return \" \".join(output_text)\n"
      ],
      "id": "SSyACSkIQV99",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfo7KFZMVMmR"
      },
      "source": [
        "## Grab a random seed Sequence"
      ],
      "id": "tfo7KFZMVMmR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBrxLJPJVede",
        "outputId": "d9bef74c-20b7-4c2c-e594-3542abd9ba48"
      },
      "source": [
        "text_sequences[0]"
      ],
      "id": "NBrxLJPJVede",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['call',\n",
              " 'me',\n",
              " 'ishmael',\n",
              " 'some',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'never',\n",
              " 'mind',\n",
              " 'how',\n",
              " 'long',\n",
              " 'precisely',\n",
              " 'having',\n",
              " 'little',\n",
              " 'or',\n",
              " 'no',\n",
              " 'money',\n",
              " 'in',\n",
              " 'my',\n",
              " 'purse',\n",
              " 'and',\n",
              " 'nothing',\n",
              " 'particular',\n",
              " 'to',\n",
              " 'interest',\n",
              " 'me',\n",
              " 'on']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjQeXoA6V3fG",
        "outputId": "85ceff00-70bd-4751-9739-b3d6741da9b0"
      },
      "source": [
        "len(text_sequences[0])"
      ],
      "id": "zjQeXoA6V3fG",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dt0LE9yV9pt"
      },
      "source": [
        "import random\n",
        "random.seed(101)\n",
        "random_pick=random.randint(0,len(text_sequences))\n",
        "random_seed_text=text_sequences[random_pick]"
      ],
      "id": "2Dt0LE9yV9pt",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otPUb2hWWaDd",
        "outputId": "833e5dbc-71e7-4343-dc8a-fd1155e53977"
      },
      "source": [
        "random_seed_text"
      ],
      "id": "otPUb2hWWaDd",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thought',\n",
              " 'i',\n",
              " 'to',\n",
              " 'myself',\n",
              " 'the',\n",
              " 'man',\n",
              " \"'s\",\n",
              " 'a',\n",
              " 'human',\n",
              " 'being',\n",
              " 'just',\n",
              " 'as',\n",
              " 'i',\n",
              " 'am',\n",
              " 'he',\n",
              " 'has',\n",
              " 'just',\n",
              " 'as',\n",
              " 'much',\n",
              " 'reason',\n",
              " 'to',\n",
              " 'fear',\n",
              " 'me',\n",
              " 'as',\n",
              " 'i',\n",
              " 'have']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QDbA1OwEWcoN",
        "outputId": "b6d8ef7e-8a49-4156-e076-baf44892f972"
      },
      "source": [
        "seed_text=' '.join(random_seed_text)\n",
        "seed_text"
      ],
      "id": "QDbA1OwEWcoN",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"thought i to myself the man 's a human being just as i am he has just as much reason to fear me as i have\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "psIKADtqWuzG",
        "outputId": "4f104966-088e-4652-e40a-79016a1d4e5e"
      },
      "source": [
        "gen_text(my_model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=30)"
      ],
      "id": "psIKADtqWuzG",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'to be afraid of him better sleep with a sober cannibal than a drunken christian landlord said i tell him to stash his tomahawk there or pipe or whatever you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puqC4QYDcFLz"
      },
      "source": [
        "## Let's predict on a selected sequence and compare it to the real text "
      ],
      "id": "puqC4QYDcFLz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SU7E02cUaHN8",
        "outputId": "58daaa95-5ce1-4371-e493-364f9e41a16b"
      },
      "source": [
        "seed_text1=text_sequences[5]\n",
        "seed_text1=\" \".join(seed_text1)\n",
        "seed_text1"
      ],
      "id": "SU7E02cUaHN8",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought i would'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "YFqFUfgkacrz",
        "outputId": "900dd8a0-2069-489b-eba8-e2b1578c842f"
      },
      "source": [
        "gen_text(my_model,tokenizer,seq_len,seed_text=seed_text1,num_gen_words=30)"
      ],
      "id": "YFqFUfgkacrz",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sail about a little and see the watery part of the world it is a way i have of driving off the spleen and regulating the circulation whenever i find'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jvaM4zuYDbd"
      },
      "source": [
        "## Exploring generated sequence"
      ],
      "id": "5jvaM4zuYDbd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sAkW1PbY7xY"
      },
      "source": [
        "with open(\"drive/MyDrive/moby_dick_four_chapters.txt\") as f:\n",
        "  full_text=f.read()"
      ],
      "id": "2sAkW1PbY7xY",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8_RoYJuZGXJ",
        "outputId": "b2fdbb73-b6b2-4ea7-9d9d-29031d1eb302"
      },
      "source": [
        "\n",
        "print(\" \".join(full_text.split()[5:65]))\n"
      ],
      "id": "k8_RoYJuZGXJ",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ago--never mind how long precisely--having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world. It is a way I have of driving off the spleen and regulating the circulation. Whenever I find myself growing grim about the mouth;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtceFB9-a0Wa"
      },
      "source": [
        "## So our model is predicting the sequence pretty well  "
      ],
      "id": "OtceFB9-a0Wa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxawEWnNcxIZ"
      },
      "source": [
        ""
      ],
      "id": "GxawEWnNcxIZ",
      "execution_count": null,
      "outputs": []
    }
  ]
}
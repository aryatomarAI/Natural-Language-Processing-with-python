{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e071cc2d",
   "metadata": {},
   "source": [
    "# Question and Answer Chat Bots\n",
    "In this Project we will Build Q&A Chat bots which will study a story and when asked a question will reply in Yes or No according to the situation in the story."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c439563",
   "metadata": {},
   "source": [
    "## Data\n",
    "We will use BaBi dataset of facebook for this project\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "## Algorithm \n",
    "We will use End-to-End Memory Networks for this project\n",
    "\n",
    "Full Details: https://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb67f07",
   "metadata": {},
   "source": [
    "## Now let's load the data and import all the tools needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73a728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf59530",
   "metadata": {},
   "source": [
    "### load the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ce29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\",\"rb\") as f:\n",
    "    train_data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8ca4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.'],\n",
       "  ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       "  'no'),\n",
       " (['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'hallway',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'bathroom', '?'],\n",
       "  'no'),\n",
       " (['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'hallway',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'office', '?'],\n",
       "  'no'),\n",
       " (['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'hallway',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'picked',\n",
       "   'up',\n",
       "   'the',\n",
       "   'football',\n",
       "   'there',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'bedroom', '?'],\n",
       "  'yes'),\n",
       " (['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'hallway',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'picked',\n",
       "   'up',\n",
       "   'the',\n",
       "   'football',\n",
       "   'there',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'John',\n",
       "   'travelled',\n",
       "   'to',\n",
       "   'the',\n",
       "   'office',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'bedroom', '?'],\n",
       "  'yes'),\n",
       " (['Sandra',\n",
       "   'got',\n",
       "   'the',\n",
       "   'football',\n",
       "   'there',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.'],\n",
       "  ['Is', 'Mary', 'in', 'the', 'bedroom', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729bbd5",
   "metadata": {},
   "source": [
    "### load the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d369e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\",\"rb\") as f:\n",
    "    test_data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f74b707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Mary',\n",
       "   'got',\n",
       "   'the',\n",
       "   'milk',\n",
       "   'there',\n",
       "   '.',\n",
       "   'John',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.'],\n",
       "  ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       "  'no'),\n",
       " (['Mary',\n",
       "   'got',\n",
       "   'the',\n",
       "   'milk',\n",
       "   'there',\n",
       "   '.',\n",
       "   'John',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'discarded',\n",
       "   'the',\n",
       "   'milk',\n",
       "   '.',\n",
       "   'John',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       "  'no'),\n",
       " (['Mary',\n",
       "   'got',\n",
       "   'the',\n",
       "   'milk',\n",
       "   'there',\n",
       "   '.',\n",
       "   'John',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'discarded',\n",
       "   'the',\n",
       "   'milk',\n",
       "   '.',\n",
       "   'John',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'John', 'in', 'the', 'garden', '?'],\n",
       "  'yes'),\n",
       " (['Mary',\n",
       "   'got',\n",
       "   'the',\n",
       "   'milk',\n",
       "   'there',\n",
       "   '.',\n",
       "   'John',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'discarded',\n",
       "   'the',\n",
       "   'milk',\n",
       "   '.',\n",
       "   'John',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'travelled',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'travelled',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'bathroom', '?'],\n",
       "  'yes'),\n",
       " (['Mary',\n",
       "   'got',\n",
       "   'the',\n",
       "   'milk',\n",
       "   'there',\n",
       "   '.',\n",
       "   'John',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'discarded',\n",
       "   'the',\n",
       "   'milk',\n",
       "   '.',\n",
       "   'John',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'travelled',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'travelled',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'took',\n",
       "   'the',\n",
       "   'football',\n",
       "   'there',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'grabbed',\n",
       "   'the',\n",
       "   'milk',\n",
       "   'there',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'bedroom', '?'],\n",
       "  'no'),\n",
       " (['Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'grabbed',\n",
       "   'the',\n",
       "   'apple',\n",
       "   'there',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'office', '?'],\n",
       "  'no')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73f2079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e272f045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515958bf",
   "metadata": {},
   "source": [
    "## Now let's try to grab the story part, question part and answer part from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfcbcba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]  # This is the first item of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e219abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'journeyed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]   # This the story part of the first item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a0a1465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "271cbf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'Sandra', 'in', 'the', 'hallway', '?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1]   # This is the question part of the first item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb009fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9d7d290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]  # This the answer part of the first item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd649b8",
   "metadata": {},
   "source": [
    "**Note-** We have only to outcomes as an answer it's either yes or no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe70192",
   "metadata": {},
   "source": [
    "### Setting Up Vocabulary of All words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c096daae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=set()\n",
    "all_data=train_data + test_data\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d67bb36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for story,ques,ans in all_data: # As each element is sub divided into three section story,question and answer\n",
    "    vocab=vocab.union(set(story))\n",
    "    vocab=vocab.union(set(ques))\n",
    "vocab.add('no')\n",
    "vocab.add(\"yes\")\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33dd5c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e326b057",
   "metadata": {},
   "source": [
    "### So we have found an vocabulary of 37 words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb0f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len=len(vocab) +1  # we add 1 to provide an extra space to hold a 0 for keras pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5cfb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len=max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddf0fa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len  # So maximum length of a story is 156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fdacca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len=max([len(data[1]) for data in all_data])\n",
    "max_question_len    # So maximum length of a question can be 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ac22e",
   "metadata": {},
   "source": [
    "### Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29ad44bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13a78141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 1,\n",
       " 'the': 2,\n",
       " 'put': 3,\n",
       " 'bedroom': 4,\n",
       " 'hallway': 5,\n",
       " 'took': 6,\n",
       " 'journeyed': 7,\n",
       " 'football': 8,\n",
       " 'garden': 9,\n",
       " 'bathroom': 10,\n",
       " 'picked': 11,\n",
       " 'to': 12,\n",
       " 'moved': 13,\n",
       " 'john': 14,\n",
       " 'discarded': 15,\n",
       " 'up': 16,\n",
       " 'kitchen': 17,\n",
       " 'dropped': 18,\n",
       " 'daniel': 19,\n",
       " 'left': 20,\n",
       " 'there': 21,\n",
       " '.': 22,\n",
       " 'milk': 23,\n",
       " 'sandra': 24,\n",
       " 'down': 25,\n",
       " 'office': 26,\n",
       " 'is': 27,\n",
       " 'travelled': 28,\n",
       " 'mary': 29,\n",
       " 'went': 30,\n",
       " 'yes': 31,\n",
       " 'grabbed': 32,\n",
       " 'apple': 33,\n",
       " 'in': 34,\n",
       " '?': 35,\n",
       " 'back': 36,\n",
       " 'got': 37}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tokenizer object\n",
    "tokenizer=Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b89c5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text=[]\n",
    "train_ques_text=[]\n",
    "train_ans_text=[]\n",
    "\n",
    "for story,ques,ans in test_data:\n",
    "    train_story_text.append(story)\n",
    "    train_ques_text.append(ques)\n",
    "    train_ans_text.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "952fe5c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'discarded',\n",
       "  'the',\n",
       "  'milk',\n",
       "  '.',\n",
       "  'John',\n",
       "  'went',\n",
       "  'to',\n",
       "  'the',\n",
       "  'garden',\n",
       "  '.']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a8c2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's create a function now for the above functionality\n",
    "def vectorize_stories(data,word_index=tokenizer.word_index,max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    # X=stories\n",
    "    X=[]\n",
    "    \n",
    "    # Xq=Question/Query\n",
    "    Xq=[]\n",
    "    \n",
    "    # Y=Correct Answers\n",
    "    Y=[]\n",
    "    \n",
    "    for story,ques,ans in data:\n",
    "        x=[word_index[word.lower()] for word in story]\n",
    "        xq=[word_index[word.lower()] for word in ques]\n",
    "        y=np.zeros(len(word_index) +1)\n",
    "        y[word_index[ans]]=1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X,maxlen=max_story_len),pad_sequences(Xq,maxlen=max_question_len),np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfd5aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train,ques_train,ans_train=vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ea67106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        29, 13, 12,  2, 10, 22, 24,  7, 12,  2,  4, 22],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0, 29, 13, 12,  2, 10, 22, 24,  7, 12,  2,  4, 22, 29, 30,\n",
       "        36, 12,  2,  4, 22, 19, 30, 36, 12,  2,  5, 22],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0, 29, 13, 12,  2, 10, 22, 24,  7, 12,  2,  4,\n",
       "        22, 29, 30, 36, 12,  2,  4, 22, 19, 30, 36, 12,  2,  5, 22, 24,\n",
       "        30, 12,  2, 17, 22, 19, 30, 36, 12,  2, 10, 22]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bc6947e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 24, 34,  2,  5, 35],\n",
       "       [27, 19, 34,  2, 10, 35],\n",
       "       [27, 19, 34,  2, 26, 35]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00337a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71b448e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index[\"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec6c3b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0., 4988.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0., 5012.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ans_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36faf88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test,ques_test,ans_test=vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dee1454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 156)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3d708e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 156)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca426d",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4edd11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the tools \n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import add,dot,concatenate\n",
    "from keras.layers import Activation,Permute,Dense,Dropout,Input\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f30bc",
   "metadata": {},
   "source": [
    "**Placeholders for inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5045f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence=Input((max_story_len,))\n",
    "question=Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6144f07a",
   "metadata": {},
   "source": [
    "### Building the Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ed779",
   "metadata": {},
   "source": [
    "### Encoders\n",
    "Input get embedded to a sequence of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99601de",
   "metadata": {},
   "source": [
    "**Input Encoder m**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b71cdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_encoder_m=Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.4))\n",
    "# (samples,max_story_len,embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204f3ff",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ffd810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the input into a sequence of vectors of sixe_query_maxlen\n",
    "input_encoder_c=Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.4))\n",
    "# (samples,story_max_len,question_maxLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d9278",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23e0057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder=Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim=64,input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.4))\n",
    "# (samples,question_len,embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77baea53",
   "metadata": {},
   "source": [
    "### Encode Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75a3be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input sequences and questions\n",
    "input_encoded_m=input_encoder_m(input_sequence)\n",
    "input_encoded_c=input_encoder_c(input_sequence)\n",
    "question_encoded=question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee8178d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape: (samples,story_max_len,question_max_len)\n",
    "match=dot([input_encoded_m,question_encoded],axes=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e67b83d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(156), Dimension(64)])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoded_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "79d89c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(6), Dimension(64)])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "72b2866e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(156), Dimension(6)])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0288ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "match=Activation(\"softmax\")(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "81db9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the matrix with second input vector sequence\n",
    "response=add([match,input_encoded_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "07d9ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will permute to alter response dimensions\n",
    "response=Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a729d6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(6), Dimension(156)])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e074ca4",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b4f5f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the match matrix with question vector sequence\n",
    "answer=concatenate([response,question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d8e7b9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(6), Dimension(220)])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e6d28",
   "metadata": {},
   "source": [
    "### Reduce with RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e98fd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c7fac8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(32)])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "72d8d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization with dropout\n",
    "answer=Dropout(0.5)(answer)\n",
    "answer=Dense(vocab_len)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ee443718",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=Activation(\"softmax\")(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6a9f8586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(38)])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839eeeec",
   "metadata": {},
   "source": [
    "### Build the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "11eeb4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model([input_sequence,question],answer)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfd089",
   "metadata": {},
   "source": [
    "## Now let's open this notebook in google colab to use it's GPU to train the model with high execution speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d639f",
   "metadata": {},
   "source": [
    "## Remaining code after this is in chat_bots_colab jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae4181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

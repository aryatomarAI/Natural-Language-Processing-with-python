{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21bacc29",
   "metadata": {},
   "source": [
    "## Spacy Basics\n",
    "\n",
    "**spaCy** (https://spacy.io/) is an open-source Python library that parses and \"understands\" large volumes of text. Separate models are available that cater to specific languages (English, French, German, etc.).\n",
    "\n",
    "Designed to effectively handle NLP tasks with most efficient implementation of common algorithms.\n",
    "\n",
    "For many NLP tasks, Spacy only has one implemented method, choosing the most efficient algorithm currently available.\n",
    "\n",
    "This means you often don't have the option to choose the other algorithms.\n",
    "\n",
    "**There are few key steps to work with Spacy:**\n",
    "\n",
    "* Loading the Language Library\n",
    "* Building a pipeline object\n",
    "* Using Tokens\n",
    "* Parts-of-speech tagging \n",
    "* Understanding Tokens attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766264f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\DELL\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# So now import the Spacy and load the language package\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp=en_core_web_sm.load()\n",
    "\n",
    "# Create a doc object\n",
    "doc=nlp(u\"Tesla is looking at buying U.S. startup for $6 million\")\n",
    "\n",
    "# Print each token seperately\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_,token.dep_) # Here pos means parts of speech and dep means dependancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ea668",
   "metadata": {},
   "source": [
    "The nlp() function from Spacy automatically takes raw text and performs a series of operations to tag, parse, and describe the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564b5f6",
   "metadata": {},
   "source": [
    "___\n",
    "## Pipeline\n",
    "When we run `nlp`, our text enters a *processing pipeline* that first breaks down the text and then performs a series of operations to tag, parse and describe the data.   Image source: https://spacy.io/usage/spacy-101#pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a90a8",
   "metadata": {},
   "source": [
    "<img src=\"..\\pipeline1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe152a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x182a98cf6c8>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x182aa5aa3a8>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x182aa5aa948>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4520d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f150ef7a",
   "metadata": {},
   "source": [
    "## Tokenization \n",
    "Tokenization is the process of breaking up the original text into component pieces(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "640d7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look into another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a79eb13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "n't ADV neg\n",
      "looking VERB ROOT\n",
      "   SPACE \n",
      "into ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n"
     ]
    }
   ],
   "source": [
    "doc2=nlp(u\"Tesla isn't looking   into startups anymore\")\n",
    "for token in doc2:\n",
    "    print(token.text,token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c3f2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look how smart our spacy algorithm is, it detects space in the sentence and successfully seperate isn't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5837b195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla isn't looking   into startups anymore"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4168d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f20eb9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1542ecbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2881c",
   "metadata": {},
   "source": [
    "___\n",
    "## Part-of-Speech Tagging (POS)\n",
    "The next step after splitting the text up into tokens is to assign parts of speech. In the above example, `Tesla` was recognized to be a ***proper noun***. Here some statistical modeling is required. For example, words that follow \"the\" are typically nouns.\n",
    "\n",
    "For a full list of POS Tags visit https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3d295a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b76cb615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].pos_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928cc31",
   "metadata": {},
   "source": [
    "___\n",
    "## Dependencies\n",
    "We also looked at the syntactic dependencies assigned to each token. `Tesla` is identified as an `nsubj` or the ***nominal subject*** of the sentence.\n",
    "\n",
    "For a full list of Syntactic Dependencies visit https://spacy.io/api/annotation#dependency-parsing\n",
    "<br>A good explanation of typed dependencies can be found [here](https://nlp.stanford.edu/software/dependencies_manual.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aba7f7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "097ce72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "546b436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PROPN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cbf608",
   "metadata": {},
   "source": [
    "___\n",
    "## Additional Token Attributes\n",
    "\n",
    "|Tag|Description|doc2[0].tag|\n",
    "|:------|:------:|:------|\n",
    "|`.text`|The original word text<!-- .element: style=\"text-align:left;\" -->|`Tesla`|\n",
    "|`.lemma_`|The base form of the word|`tesla`|\n",
    "|`.pos_`|The simple part-of-speech tag|`PROPN`/`proper noun`|\n",
    "|`.tag_`|The detailed part-of-speech tag|`NNP`/`noun, proper singular`|\n",
    "|`.shape_`|The word shape â€“ capitalization, punctuation, digits|`Xxxxx`|\n",
    "|`.is_alpha`|Is the token an alpha character?|`True`|\n",
    "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc995278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "# Lemma Base form of the word\n",
    "print(doc2[3])\n",
    "print(doc2[3].lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cdaa52f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla: Xxxxx\n"
     ]
    }
   ],
   "source": [
    "# Word Shapes:\n",
    "print(doc2[0].text+': ' + doc2[0].shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a45393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Boolean expression\n",
    "print(doc2[0].is_alpha)\n",
    "print(doc2[0].is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ddc43a",
   "metadata": {},
   "source": [
    "## Spans\n",
    "Large Doc objects can be hard to work with at times. A **span** is a slice of Doc object in the form `Doc[start:stop]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18a69c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9fbcf20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Life is what happens to us while we are making other plans\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "life_quote=doc3[16:30]\n",
    "life_quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd2cdea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f6595",
   "metadata": {},
   "source": [
    "## Sentences\n",
    "Certain tokens inside a Doc object may also receive a \"start of sentence\" tag. While this doesn't immediately build a list of sentences, these tags enable the generation of sentence segments through `Doc.sents`. Later we'll write our own segmentation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87c542ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4=nlp(u\"This is the first sentence. This is the second sentence. this is the third sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84c85d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is the second sentence.\n",
      "this is the third sentence.\n"
     ]
    }
   ],
   "source": [
    "for sen in doc4.sents:\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc956f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start  # Is index 6 start of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea1aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
